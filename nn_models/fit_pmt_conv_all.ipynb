{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network for classifying Root data fits.\n",
    "\n",
    "\n",
    "Here, we define, train, and save new convolutional models as well as some \n",
    "simple model evaluation. We define hyper-parameters, number of layers, and \n",
    "training and testing datasets. \n",
    "\n",
    "Here, at the final layer, the network takes into account chi squared per degree of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load some packages\n",
    "\n",
    "# Keras packages for network\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, Conv2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "# For saving model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import concatenate, Lambda\n",
    "\n",
    "# Some items for plotting and drawing\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Need numpy\n",
    "import numpy as np\n",
    "import nn_utils as utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load root fit data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(m, height, width, channels): (1396, 236, 348, 3)\n",
      "m_dev: 129\n",
      "y: (1396, 1)\n",
      "params: (1396, 54)\n"
     ]
    }
   ],
   "source": [
    "# Define image file path\n",
    "im_path=\"/media/brady/4be7777f-c84c-40ca-af3a-b8c6e4f2f90d/brady/Projects/fit_pmt/images/png_fit_nn/\"\n",
    "\n",
    "# Load dataset\n",
    "x, y, params = utils.load_dataset_all(im_dir=\"train\", log=False, im_path=im_path)\n",
    "x_dev, y_dev, params_dev = utils.load_dataset_all(im_dir=\"dev\", log=False, im_path=im_path)\n",
    "\n",
    "# Grab dimensions of picture\n",
    "(m, h, w, c) = x.shape\n",
    "m_dev = x_dev.shape[0]\n",
    "input_shape = h, w, c\n",
    "num_params = params.shape[1]\n",
    "\n",
    "# Print dimensions\n",
    "print(\"(m, height, width, channels): (\" + str(m) + \", \" + str(h) + \", \" + str(w) + \", \" + str(c) + \")\")\n",
    "print(\"m_dev: \" + str(m_dev))\n",
    "print(\"y: \" + str(y.shape))\n",
    "print(\"params: \" + str(params.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: good\n",
      "label: [1]\n",
      "params: [ 0.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  2.000000e+01\n",
      "  5.000000e-02  6.144692e+02  2.252700e+00  1.000000e-02  2.560000e+00\n",
      "  4.000000e+00  2.252700e+00  5.000000e-01  5.000000e-01  1.000000e-03\n",
      " -1.000000e+00 -1.000000e+00 -1.000000e+00 -1.000000e+00 -1.000000e+00\n",
      " -1.000000e+00  0.000000e+00  0.000000e+00  5.000000e-01 -1.000000e+00\n",
      " -1.000000e+00 -1.000000e+00 -1.000000e+00 -1.000000e+00 -1.000000e+00\n",
      "  1.000000e+00  1.000000e+00  6.400000e-03  6.130692e+02  1.706800e+00\n",
      "  5.000000e-02  5.411800e+00  1.132900e+00  1.556800e+00  1.765000e-01\n",
      "  8.235000e-01  2.000000e-04  1.620000e-02  1.270000e-02  1.000000e-03\n",
      "  8.910000e-02  1.870000e-02  1.070000e-02  2.800000e-03  3.000000e-03\n",
      "  6.254000e+00  1.768000e-01  7.300000e-03  4.130900e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fab5abc1860>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD8CAYAAABTjp5OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3X18lOWd7/HPRSYYZGgGCibKIEHDQrtRUo0Y1yi2tQ2IXejBVnvcLfUFte2qXTzWLS50W1td7VYrtfXYrQ/oVrfYQn1YFbLCUVrUaIObaFDQUVAGCI8OMtggA9f547onCWlCJmTueUi+79drXnPP/fjjzvDLlevpNtZaREQk9w3KdgAiIpIaJWwRkTyhhC0ikieUsEVE8oQStohInlDCFhHJE74lbGPMVGPMBmNMxBgz36/riIgMFMaPftjGmALgTeBzQBT4E/AVa+3rab+YiMgA4VcJezIQsda+Y639CFgCzPDpWiIiA0LAp/OOBjZ3+BwFzu5u55EjR9qysjKfQhERyW1r167dZa0d1dN+fiXsHhljrgSuBDj55JNpaGjIVigiIllljHk3lf38qhLZAozp8DnsrWtjrf2VtbbKWls1alSPv1hERAY8vxL2n4DxxphxxpjBwGXAEz5dS0RkQPClSsRamzDGXA3UAQXA/dbadX5cS0RkoPCtDtta+zTwtF/nFxEZaDTSUUQkTyhhi4jkCSVsEZE8oYQtIpInlLBFRPKEEraISJ5QwhYRyRNK2CIieUIJW0QkTyhhi4jkCSVsEZE8oYQtIpInlLBFRPKEEraISJ5QwhYRyRNZe6ZjrlizZg3r168nEBjwt0JkQEokEkycOJGamppsh9KjAZ+l1q9fz8SJEwmHw9kORUSyIBqNsn79eiXsfBAIBAiHw5SVlWU7FBHJkkgkku0QUqI6bBGRPKGELSKSJ5SwRUTyhBK2iEieUMIWEckTSthZdvDgQd555x2stdkORURynBJ2FkWjcSZPXseECSewaVMs2+GISI5Tws6itWuDWDuB2bNb2L9/eLbDEZEcp4SdRY2N8LnPDeHmm8dRV5ftaEQk1ylhZ0ksBs3NUFoKJSUF1Ne7dSIi3VHCzpJYDFpaoLbWfW5pUcIWkaNTws6iQACCwfbPTU3Zi0VEcp8SdpY0NUEi4ZI2wMSJMX79641s3rwtu4GJSM5Sws6SxkaornZ12ADPP/9vLF/+PosWLSEej2c3OBHJSUrYWRQMtpewzzlnCEOGDGHChLMpKirKbmAikpMG/HzY2ZBIQDx+ZP31D3/4f9iz5zj27h1EIKDfoyLyl5QZsqClBerrobKyfd3o0UOprAywY8cgEonsxSYiuUsJOwuSjY2TJh25vrLSJfKWluzEJSK5TQk7w+LxOHfeeSf19fV84QtfYM2aNW3bpk93DZFnnfUQkyf/DcuWLSOh4raIePqUsI0xm4wxrxljGo0xDd66EcaYZ4wxb3nvmiSjg6KiIqqqqiguLuass85i3LhxbdsCAddrZNeuStat280LL7xAa2trFqMVkVySjhL2p621ldbaKu/zfGCVtXY8sMr7LJ5AIEBFRTXjxo3nuuuu46STTjpi+/TpUF4eZtq0hcybN49gx5ZJERnQ/KgSmQE86C0/CMz04Rp57ZlnBhEOBxg9eijGmCO2lZfDZZeFOHTo70kkSnnnnXfYs2eP5ssWkT4nbAv8tzFmrTHmSm9dibU2OVyvBSjp4zX6nXgcKiogFPrLbYEAXHopRCLw1a9u50tfupb58+ezdevWzAcqIjmlrwm7xlp7BjANuMoYc37HjdYVC7ssGhpjrjTGNBhjGnbu3NnHMPqX8nJYuBA2bSrllVeu5OmnB7NmzUYOHDikkrbIANangTPW2i3e+w5jzKPAZGC7MeZEa+02Y8yJwI5ujv0V8CuAqqoqZaEOAgGYNQuCwQD33jud1177DDffPJgXXniJ2to4n/vcpyksLMx2mCKSYcdcwjbGDDXGDEsuA58HmoEngNnebrOBx/sa5EAUCLgGyMWL4aGHDnH48Kv84hchvvOdeurrG7IdnohkQV9K2CXAo16jWQD4T2vtCmPMn4DfGmPmAO8CX+57mANXKARVVUXceOMefvjD/bz77jW8957p+UAR6XeOOWFba98BJnWxfjfw2b4E1Z8lnzRTXZ36MYFAgL/92/MpL/+AG274GEuXFnD55f7FKCK5SSMdM6zzk2ZSVVhYyKRJH+cb3yigsdGf2EQktylhZ0HnJ830xpQpbs6RPXs+UI8RkQFGCTvPBAJxTjnlDmprf66+2SIDjObDzrB4nD5NnxoMBpk37zI++GAII0YMTV9gIpLzVMLOsLo6N8FTV6McUzVmzImsXx9i9271xRYZSJSwM+xow9J7a+3avp9DRPKHEnaeqq5GvUVEBhgl7DxVWur6c8di2Y5ERDJFCTtP1da6/txK2CIDhxJ2nkrWgTc1ZTcOEckcJew8VVqqemyRgUYJO08VFFiGDdtPY2OCPXsOZzscEckAJewMSk78lI7HNG7dupV1637KH/8YYcWKej1dXWQAUMLOoGOd+KkrGzdu5PXXX2b//hgNDQ16urrIAKCEnWF9mfipo7PPPpsf/GAh48aN5/TTv6qnq4sMAJpLJE8VFhYya9bZbNoETz0FM2emZ/SkiOQulbDznPpjiwwcSth5LlkTEo9nNw4R8Z8Sdp4LhVyf7Lq6bEciIn5Tws5zoZCb/U8lbJH+Twk7g5qa3MMLAj409fb1wQgikvuUsDOosdENJy8tTe95Kyuhvt41PopI/6WEnWHBYPpL2JMmwaFDB3jnnXc5ePBgek8uIjlDCbsfiMdjbN26g2uuuZ9Vq1ZlOxwR8YkGzvQD77//Bscdt4tIZCiRSARrLcaYbIclImmmhN0PVFdXcdFF+9m8uYwZM0JK1iL9lBJ2P1BYWEg4HCIaDTFsWLajERG/qA47Q9avj7NkyS4efvifWLFiRdrPP2uW6yUSjab91CKSI5SwMyQabWHXrha2bHmqrZ45nTTiUaT/U5VIhpSXl3Piibu5+OJ/ZMaMaWmvZ9aIR5H+Twk7g0aMGMGcOXMYM6bAt2skRzz6MZpSRLJLVSIZZIyhoMC/ZK0RjyL9mxJ2PzJpkitZa04Rkf5JCVtEJE8oYfcjydJ1U1O2IxERPyhh9yOlpW42wMbGbEciIn5Qws6QTMxXnXwiu+bGFumfekzYxpj7jTE7jDHNHdaNMMY8Y4x5y3sf7q03xpg7jTERY8yrxpgz/Aw+n9TVuRKw3082V08Rkf4rlRL2A8DUTuvmA6usteOBVd5ngGnAeO91JXB3esLMf/G4G9jid8IeOzbG3r17eP75lzQ3tkg/02PCttb+AdjTafUM4EFv+UFgZof1/2GdeiBkjDkxXcHK0SUSCd5883VisX08/PA6duzYke2QRCSNjnU8XIm1dpu33AKUeMujgc0d9ot667YhvgsEAsycWc3LLxuGDv0aJ52kaVZF+pM+NzpaN4tRr2cyMsZcaYxpMMY07Ny5s69hiGfw4EEMG2YYNGiQ5sUW6WeONWFvT1Z1eO/Jv723AGM67Bf21v0Fa+2vrLVV1tqqUaNGHWMY0h31FBHpf441YT8BzPaWZwOPd1j/Va+3SDWwt0PVyYAVi0Fzs+tylwnqKSLSP/VYh22M+Q1wATDSGBMFvg/cCvzWGDMHeBf4srf708BFQAT4ELjCh5jzTizmkmdtbWaupzlFRPqnHhO2tfYr3Wz6bBf7WuCqvgbVHyUHtWTqWskh6mVlmbmmiPhPIx37IQ1RF+mflLD7oUyW5kUkc5Sw+zH1FBHpX5Sw+yn1FBHpf5Sw+yn1FBHpf5Sw+6lwGKqq4MEHe95XRPKDEnYGZKMuOdnweOjQIVxvSxHJd0rYGZCpubC7smrVSyxf/kzmLywiaaeEnQGZmgv7yGvG2bjxUerr4bvfvSNzFxYR3yhh91NFRUV8/vMljBo1nLPOOifb4YhIGhzrfNjSRzHv3a9CdyAQoLq6mvHjD3Pdddf5dBURySSVsLMgClwD3AX42RY5ePAgIEAkMtTHq4hIpihhZ8EjwHpgBe5xPX7RnCIi/YsSdobFgHqgxvu81sdrJbv2xeM+XkREMkYJO8NiuFL1bKAa8LvwmxyiLiL5Twk7w5q895FAKdBMewOkH5JD1EUk/ylh+yyROLJKohFXsi4FanGlbT8Ttoj0H0rYPotGoaEBZs92PULiQBDXnzL57qfknCIikv+UsDOoBdfgWOl9DuCSeFO3R/SdHmYg0n8oYWdQApekJ3mfS8lMw2Mw6B4ELCL5TQk7i5LVIn6rrVXCFukPlLAHAPXFFukflLCzrAaY6PM1QiE3xauI5DclbJ81Nbmufcm+0DM5csKnCcBjPscwdOhBXnzxNTZv3uzzlUTET0rYPmtsdPN5lJbC4966jgk7gb/ziQDs2LGD5ctXsGjRIuKqGxHJWxoDlwHBoCthZ6vdb+jQoRx//GTOPHM/RUVFWYpCRPpKCdtH1loOH7a0trZy8GAhFBZmJY7i4mImTDif6mpLIKA/qkTylRK2j7Zu3Upj43beeGM9Z0w+jvIZMyjtNLFHANcf20/GGAoLYdAg4/OVRMRPKm75aOPGjbz1VoQtW6L8/oUXWNLayoRO+5TiGiL9lki4BlARyV8qYfuopqaGSy91y7O/D1fwl0+YCeAeZuC3Cy+ENWtg+nTN3ieSr1TCzgGZeJh6cl7sFr+7pIiIb5SwfdR5atXuXI6/z3aE9nmxE35fSER8o4Tto5YWV6qt9Kbn6zxoJqkV//tiQ+q/QEQkNylh+yg5wnHSpK4HzbTth/8l7FDIDd7REHWR/KXmpwzJ9mR5oRBUVKiELZLPVMIeQIJBaG7WVKsi+UoJO0NCZKY3yNHU1rp6dSVskfzUY8I2xtxvjNlhjGnusO4HxpgtxphG73VRh203GGMixpgNxphavwLPJwncA3cv72Z7phJ5ck4TEclPqZSwHwCmdrH+Dmttpfd6GsAY80ngMuCvvWP+rzGmIF3B5qsW4EZcb5CuhGhvlPRTQYHlo48O8+KLH3Lw4MEMXFFE0qnHhG2t/QOwJ8XzzQCWWGsPWGs3AhFgch/i6xeSU6gerSdIJmopDh/eSlFRI9///mM88cQTJNQpWySv9KUO+2pjzKtelclwb91ooOMs+VFv3YAUj6c+UCUT1SKbN29k2zY3t8kLL7xAa2t3ZX4RyUXHmrDvBk4FKoFtwO29PYEx5kpjTIMxpmHnzp3HGEZuW7bMzeFRVtbzvpkoYdfU1PDb336ZM874J6655naCwUw8AlhE0uWYEra1dru19pC19jBwD+3VHluAMR12DXvrujrHr6y1VdbaqlGjRh1LGHkjOYXq0dr7MtXwGPIupJn7RPLPMSVsY8yJHT5+EUj2IHkCuMwYc5wxZhwwHni5byHmvw24Yek9zXudiVJ2aal7ZFljYwYuJiJp1WMnL2PMb4ALgJHGmCjwfeACY0wlYIFNwDcArLXrjDG/BV7HtbFdZa095E/o+WON9360m10PzML/knYg4Lr3JevX1c1PJH/0+N/VWvuVLlbfd5T9bwZu7ktQ/UFyoqVUq4krgUw9bbGyEm67zQ2iCYczdFER6TONdPRJ55n6erICyNQ0H5pqVSQ/KWH7pONMfanoqVEy3TTVqkj+UcLOETNxjZOZoKlWRfKTErbPEsBEoKaH/Vpo72rjt+RUqy0tqhYRySdK2D5rAR6Dv3haemdl3itTKith9eoDvPzyu5pXRCRPKGH7LJV5RAAavVemnHpqnB07tvKtb32bVatWZfDKInKslLAHqF27tmFtAZHIUCKRCNbabIckIj3QsAmfLFsGI0e6+uLuHr7bUQ2wC1cSz8QP5YILxnPnnXDbbf/JzJlgTAYuKiJ9ohK2T+Jx17C32svUPSXsCbi67kw8PT1J/bFF8osSts9ipDZHSBGZHe0I7claE0GJ5Acl7BzRimt0zOQM1ZoISiS/KGHniFR7k6RT54mgRCS3KWH7pLk59YmfwNVxz/Qtmu5VVro5T1oyWXkuIsdECdsnLS1QW+vmpb0ghf2TjZKZeBhvR2ee6d7Xrs3whUWk15SwfRIIQCLoJgtPcf6nlBso00n12CL5QwnbRzHgATKfhHsjEIATTjhMY2OCLVv2awCNSA5Twh7gEokExcX1/PGPEf7lX37K1q1bsx2SiHRDCXuAa21tZf36BuLxfbz44mts3Lgx2yGJSDc0NN0HBw8eZPfuPxOLHWYmoZSf05jp4ekAwWCQb3/7q7z55nGMH/9Tzj67JENXFpHeUgnbB/v376e19b/48faXiJH6g3VPBX4JRP0LrUtlZSFuvXUI9fVhNmwozPDVRSRVKmH7oLi4mC9+8YsUfiYNyS+R6PpJA+FwWh95Hg67V12dmwNFRHKPErYPjDEcf/zx0Nd8HY3CfffBypVuOGLM628SDMIll8Cll0J5eVoSdyjkuvfV17vLhFL9s0BEMkZVIj4KkXp1CLjfnm0P441G4YYbXAfpyy5zGbSoCMrKXGl76VL40pfcPK5pGldeW+sK87Fc7ocoMoApYfsgFnODZgBm9OK4UryH8SaTNcB3v+uKveEwPPooLF7sxpPfcYeru5g/P21JO1mqfuWVQ30+l4iknxK2D2IxOLvWzW/dGwFgPbBm2TK34qqr4K673PItt8DEia6E/ZOfwIMPwoIFrh7jppsgEulz3MlRj7ff/pKe8yiSg5SwfdKbiZ/aJBKurrqkxJWs6+rc51tucSXspHAY1qxxE1nfcourx77xRleN0getrXF27nyU+nrYsWNHn84lIumnhO2DePwYD4xECC1ZQqi62s3GdO+9rkTdOfsnEu41f74rgcdirk77vvv6VDVSVFTERReVMHr0aIYOHXrM5xERfyhh+6CuDt4N9XIATCIBjzzCjLvugjVriN10k1v/2GNwzTXtpedoFG6+ub3v3ZNPtm9bsqRPVSOBQICZM6v58pdPZujQ4mM+j4j4QwnbB/E4bApBNa4hMSV1da5EnUjwWFkZsalTYflyVz/d2OgaIR9+2CXvxkb49a/h1ltd6fsnP4GFC6G1tc9VI4MHD+K88wzbt+upvCK5RgnbR0F6UcK+9173Pm+eq5OeM8eVoi+9FH7zG9ff7jvfcVUkP/+5eyT79Onuc1OTq/O+9VbXo+T66/uUtM88U/Nji+QiJWyf9Loae80aNxgmEiGRSBCvrGzftm5d+2jHXbva67RDIfi7v4MVK2DTJpg1C772NVeN0oekXVoKDz2k/tgiuUYJO81iMfd4sHrcU9BTPqi6GsrLCa1ZQylQl9wWicCiRa50fdttLrGvXt1+7JQprtfII4+4z5de6krdS5e6apRjyLqBgMv1fex0IiJppoSdZrGYKwQHSPFJM7EYfP3rrmT80EOE7rmHinCYlkSCxI03uqT7u9/B7NnutXy5q6/u2BtkwQJ47jlXqi4qcvtPneqKyaedBk891et/x969/8zkyU3Mm/dL4sfc7UVE0klzifgkpc51iYRLptGoS65Tp0J5OZXAbS0ttNTXE7766iP7YJeXu6qT555zddfJJ+jGYu4cjz3mRkImk2ws5urHp0/vVfw1NUVs21ZMYeFMioqKenWsiPhDCTvNmppcHi4lhXlEIhHXUDhzpqtHmTMHAgEmxeMEiopIJEcydhQIuLrqadOgqgpqatwkIOBK4y0trkpkxQq3b2mpS+69nNHp1lvnUVw8iEgkSEvLkb8zRCQ7VCWSZo2NLsdW0EPC9vpdA65bRnW1+5ysBmltdcm480x80Sjcfrtb/u534brrXG+SigqYO9ftP2eOm3ck2dUvFnMl+V4Mqhkx4mPMmRMkEoF777UcOKD5RUSyTQk7jZIjy4tSGZYeibiGwZkzXR+6pUtdg+KTT8Jzz5GIx4k3NrYn2WT1yTXXuOWqqvZRjknJBsgf/9iVrBcsaE/ixzDfSLL25f779/Cv/3ofmzdv7tXxIpJePSZsY8wYY8yzxpjXjTHrjDH/6K0fYYx5xhjzlvc+3FtvjDF3GmMixphXjTFn+P2PyBUtLa5KubSyhx4inUvXjz3mZuG75BIIBAgtXEhpWRl1q1e7mfhaW937TTe5+ulbbnGNlJ17jCS7+TU2upJ4INA+Z3Yk0utBNYEAfOpTG/jwwz3cdttaFi36hRogRbIolRJ2ArjOWvtJ3OC9q4wxnwTmA6usteOBVd5ngGnAeO91JXB32qPOUbt2xdi7dw/x1peO3kOkrg4eeKC9GqSy0iXbpUth6lRCs2ZRUVTk+nLfdBNce63r2jdvnis1h8OuNF1T85cdpqdMcbP6JadcLS9382lXVroHIfz7v/eqq9+ZZ4aYMSPKkCHXM2HCdDVAimRRjwnbWrvNWvuKt7wPeAMYjZvq+UFvtwdxUznjrf8P69QDIWPMiWmPPMfE43EWL36FN998m9v//a7ud0z22ti1CxoaXGPjggVu4iZoa3gE4PLLXVL/5S9dcp41q31bKOSOi0bbS9mxmHtdcIGbV+SRR1wdzaWXuuPnznXnuuuulOuzTzrpBH74w8mcd14Zq1fXEI+rnVokW3r1v88YUwZ8CngJKLHWbvM2tQDJx22PBjpWdka9ddvox4qKihg8eDJDhixh0EVndN/guHq167URj7vRib/4RXuvjoUL27pjBONx6uNxYtEooQsucFUanbtrlJW5kvOiRa4apLnZ7QPuF8LVV7tSe0WFe1+4EC68sG3OEubM6bH7hzGG0aOHMneumxzwqadc/k/j4yRFJEUpNzoaY4LAMmCetfaDjtustRawvbmwMeZKY0yDMaZh586dvTk0RwWAIJdddjFfmfu1rhN2LOaqQpJVEhdc4PpHb9rkkmuye14sRu2SJbTE48QWLHBzh0QiR45cXL/eNS6uWeOS9ZNPuobIu+92E0MtWuSGsEej7pdDPO5K3ZWVrk78ppt6NXy9thamT/8zCxfGefzxdXrAgUgWpJSwjTGFuGT9sLX2997q7cmqDu89OeP9FmBMh8PD3rojWGt/Za2tstZWjRo16ljjzxnJBscLp5YS6Kq/c7KXx3PPuc/hsKuiiMfddKnTp7ePCb/2WkLLlkEoRFNNjauTXrjQJebHH3cl6SuucO833eSS/a5d7d37yspcMXjuXJec58xxJflIxO2/a1f7cyFTTNoFBZYRIx5ly5bV3HBDKytXvpHW+yciPevxD1tjjAHuA96w1v60w6YngNnArd774x3WX22MWQKcDeztUHXSbyVntxt9pptH5C8kk2Us5hLz3Lnw13/d/uzGUKj9wbtA6R13UF1aSiMwIxCAGTPc9oUL3b433eQaGEMh19OksdFVdZx7rluX7I/d2OhK4osXu+tcfbV7DwbdL4ulS93nn/zkqNUjxhhOP30Ep532Im+/PY+77x5EaelGxo4tZvjw4biviYj4KZUS9rnA3wOfMcY0eq+LcIn6c8aYt4ALvc8ATwPvABHgHuAf0h92bkmOCp85E+rCritNm0TCdac77TRXjTFxIvzP/7jeG+ed5xJ5JAJjxrh9ampg8WICEycyu7WVFbEYzddeC5/+tOtbvXy5O/bMM9tHLobDLiFXV8M557hS8403uobMsjJXXXLDDe468+e781x8Mbz4outKuHQpjBsHX/jCUQfYTJ06lbVrb2TTpkJOOOFlzj33MH/1Vy/xX//1it+3WERIoYRtrV0DdFd8+mwX+1vgqj7GlVdWr3aF33Onw+10SNiJhOtel2zkS1aDPPKI63tdVeWSbDzuqjcSCTdUvaUFyssJr1xJ+PLLqZsxg4pvfMMl6mTp/PrrXS+Rt99ub3CMRl0VyL33ukQcDrukPm+eq9MuL3fbi4pcF7943CXvoiK3/OST7ly33up6qHQjFAry/e9XMHr0+yxe/HkeegimTTtIYWFhJm63yICltv4+2rQpxj33HEdFxW4KxpYQpZDa5Ma6OjctajTqEuPcua4rX7LR79RTXUJfudKVnGMxV5+9aBEkEoSqqqgoL2dNWRlz8Ia6x2IwenT7yMhQyE0aVV3d3mj5ve+5BNyxF0hjo7tush/388+70nY06s4RCrlzR6Ou2iQYbK9y6cKYMSfyz/98AuXlh7j22t08/PAQZswo5mMfO0xBQYG/N11kgNLQ9D6w1vL44zGeeeYNVj//bW5Y+xJhXCsrTz3l5q+ORl3yq6pyvTQCAfjRj9wJvvc9l0gXLnT7PfigKylfeKF77dpF5cMPE4nFiK5e7ao5vv51+Na3XKkZ3JNnrrrqyDlFrr7a9Ty5/np3vk2bXH3Nrl2uPrupCc4+uz0xl5W5Evm8eS6Zx2JuJOUVV7hGzmi0y2qS444r4NOf3sO4cf/EwoVDmT37A37606fYvHkb1loOHdL8IyLppBL2MbLW8t57h3n22bGccMJKSs4tYcO4cfwCCMVi8M1vukRXXu4SZSTSNn1q2xDxCy90vUO2b3eJOBx2pd5Jk1zS/NnPmHLbbUysqODHoRA/B/dE9dpaV2IfOdJVX1xzjfuFkJTsxldf7+qlAwF37kTC/YKYO9cl6mDQnaO52cV4ySXuvNGou/5jj7leLeGw2zZrVns1i6ek5OPceONXWL78D9xzz4esXDmWl15q5Ywz3qCo6DW+9KXzOemkExg0aJAaJkX6SAm7F6y1HD58mEOHDHV1b3PXXSGCwSC/e/Ri/vOU/0WJMUxpbnal2GRXueRgl9JSV9JdscJVX8yc6bZdf71LpAsWwO7dLqE+9FDbAJjQ177G3zU3M++qq3iqpIRLm5oILFvWXmc9cqQ7ZsUKVxd98cVu3dy5rsrlxz922++4o71nyLJlrkolFHL7tbS41733ts+jnZQcPbl+vdvecUrXYJDCUIhp06YxadJWDhz4GWvXBtm+/SpuvtkCn+KFF1qZMGEtVVWFVFZWkEhE+fjHiykuLqagoKDtnhYUFHDo0KG2xN5xWUQc49oIs6uqqso2NDRk5dqLFy9m0qRJhEIhSkpK2L59O6GQS8TRaPSI5aamvTQ0HOTAgbP4/W+3cnDnGiq/GWXij77BmliMhTfcwPTnnmvEgyfHAAAJOElEQVR//mJSMNje2BcOt5eAYzE3kGXiRFcaTiRclUZjo0uKoRAEg8RWruSa+fNZM2UKX3vkEWY98AAVu3a5fZJJeMUKd43ycneN5Mx8yYQbDrcPT0wk2mNM1l93XNeT5DzbgYCLv7ISO3Qo70+eTCyRwAwawa23/Jrnnx/GjoMj2J2oYvjwEYRCoyks/AMTJ4Y555wiLrxwFO+++y7vvPM2Z55Zxdq1DZxyyqmMHTuWZ599lE984kSmTJnC9u3bKS4uZu/evYTDYeLxOLFYrMufV3FxMQDDhg1r2y+VY1I5d3J53759ACnH03m/XIunp+998pgxY8a0NSwfPHiQzZs3+3Lvu7vO8OHDAXj//fdTOncoFGLEiBFHfHWttW3HJ4+JxWI0NTVxxRVX9Dp/pIsxZq21tqqn/QZ8Cfv9SZO4bt8+PohGOX3QIF5tbubksWMZM2YMz3da3vjeFGLHgR1sCM7ZSU0wTuO55xKoq2PhAw9Qu2JF1wkvWWqNx11JtaPGRvcClwCTD9pN9o/GNTbeMn8+982dy2MzZrC0tpZLHn/8yGtVVBx53pqavt+c3jhwAN58EwIBLO9x/EUnU33ePl4fnGDPRxvYX3gCsY/GcujwdNYDTx/6kJ81BPjzn0/hw4OlfOz1j/HBwXM5/r3jGbJzCLsPjubk93fz6b17aWhuJjxmDNHNmzk3FGLz5s289+67Xf68wmPcmK2xY8e27ZfKMamcO7n87nvvAaQcT+f9ci2enr73yWPOGzGC4V512Pv79/NHn+59d9c5zVv3WornPnnsWCo7JexD1rYdnzzmY8XFfGFSSg/0y7oBn7A/MXEiv3z0UbZs2UJ8/36i0Sj79u3jwIEDrN+w4YjlmppR7Nq5k/POP5/hoUqgkm82NjIlGiVUVXVkPXKahYEFgQBzGhpYW1VF44IFvl2rrwzul0wIN+S1tsO2P//5zxQEAqxYvpJza2ra/sOddvrpvPbqq+3/4dZ8xMljK9i5cyfrN2xg+/btvP/++5SUlBCJRLr9eW3fvh2Agx991LZfKsekcu7k8qtNTQApx9N5v1yLp6fvffKYcePGtSXS6ObNXe6Xjnvf3XX+avx4ANY1N6d07n379lHZKREfaG1tOz55zOiTTuITX/yiL/8X0m3AJ+wLCwtZNHw4b7S0cM7YsdRv28aEUIhPjBzJYwUFRyz/73Hj+LCkhDFDh9LW49irEsiEALT1QpmRkSum36HBgzHGMKeignAwSHzMGGLDhlEyahTbKyra/6T1luPxOEsLCjhl1Cje/uADZo4cyYbdu7v9eZ3iTXNwWof9UjkmlXMnl1/1rpFqPJ33y7V4evreJ4/5cijUNufE5lCIv+liv3Tc++6u83mvmmSK9/81lX9D5yeZHiwsbDu+4zEX5skYggFfhw2k1PB16NAh9S/OkuTPIfkz6unnBW4ofcf9ejom1f2S5wX6dO5ci+do3/uOx3T1c/Hj3nd3HaBX5+6q0bq7Y7Ip1TpsJWwRkSxLNWFr4IyISJ5QwhYRyRNK2CIieUIJW0QkTyhhi4jkCSVsEZE8oYQtIpInlLBFRPKEEraISJ5QwhYRyRNK2CIieUIJW0QkTyhhi4jkCSVsEZE8oYQtIpInlLBFRPKEEraISJ5QwhYRyRM58YgwY8xOYD+wK9uxHIORKO5MUtyZpbgzY6y1dlRPO+VEwgYwxjSk8kyzXKO4M0txZ5bizi2qEhERyRNK2CIieSKXEvavsh3AMVLcmaW4M0tx55CcqcMWEZGjy6UStoiIHEXWE7YxZqoxZoMxJmKMmZ/teI7GGLPJGPOaMabRGNPgrRthjHnGGPOW9z48B+K83xizwxjT3GFdl3Ea507v/r9qjDkjx+L+gTFmi3fPG40xF3XYdoMX9wZjTG12ogZjzBhjzLPGmNeNMeuMMf/orc/pe36UuHP6nhtjiowxLxtjmry4b/TWjzPGvOTF94gxZrC3/jjvc8TbXpaNuNPCWpu1F1AAvA2cAgwGmoBPZjOmHuLdBIzstO7fgPne8nzgxzkQ5/nAGUBzT3ECFwHLAQNUAy/lWNw/AL7Txb6f9L4vxwHjvO9RQZbiPhE4w1seBrzpxZfT9/wocef0PffuW9BbLgRe8u7jb4HLvPW/BL7lLf8D8Etv+TLgkWzc73S8sl3CngxErLXvWGs/ApYAM7IcU2/NAB70lh8EZmYxFgCstX8A9nRa3V2cM4D/sE49EDLGnJiZSI/UTdzdmQEssdYesNZuBCK471PGWWu3WWtf8Zb3AW8Ao8nxe36UuLuTE/fcu29x72Oh97LAZ4Cl3vrO9zv5c1gKfNYYYzIUblplO2GPBjZ3+Bzl6F+YbLPAfxtj1hpjrvTWlVhrt3nLLUBJdkLrUXdx5sPP4Gqv6uD+DlVOORm39+f2p3Clvry5553ihhy/58aYAmNMI7ADeAZX2o9ZaxNdxNYWt7d9L/DxzEacHtlO2Pmmxlp7BjANuMoYc37Hjdb9zZXz3W7yJU7P3cCpQCWwDbg9u+F0zxgTBJYB86y1H3Tclsv3vIu4c/6eW2sPWWsrgTCulD8xyyFlRLYT9hZgTIfPYW9dTrLWbvHedwCP4r4o25N/znrvO7IX4VF1F2dO/wystdu9/5yHgXto/xM8p+I2xhTikt7D1trfe6tz/p53FXe+3HMAa20MeBY4B1e1FPA2dYytLW5vezGwO8OhpkW2E/afgPFe6+5gXIPAE1mOqUvGmKHGmGHJZeDzQDMu3tnebrOBx7MTYY+6i/MJ4Ktez4VqYG+HP+OzrlPd7hdx9xxc3Jd5PQDGAeOBlzMdH7heH8B9wBvW2p922JTT97y7uHP9nhtjRhljQt7yEOBzuPr3Z4FLvN063+/kz+ES4P95f/Hkn2y3euJazN/E1UEtyHY8R4nzFFwLeROwLhkrri5sFfAWsBIYkQOx/gb3p+xBXF3enO7ixLW43+Xd/9eAqhyL+9deXK/i/uOd2GH/BV7cG4BpWYy7Blfd8SrQ6L0uyvV7fpS4c/qeA6cD/+PF1wz8i7f+FNwvkAjwO+A4b32R9znibT8lW9+Vvr400lFEJE9ku0pERERSpIQtIpInlLBFRPKEEraISJ5QwhYRyRNK2CIieUIJW0QkTyhhi4jkif8P9ZjNi5DAeNEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print an image\n",
    "index = 420\n",
    "this_image = x[index]\n",
    "if y[index] == 1:\n",
    "    print(\"label: good\")\n",
    "else:\n",
    "    print(\"label: bad\")\n",
    "print(\"label: \" + str(y[index]))\n",
    "print(\"params: \" + str(params[index]))\n",
    "plt.imshow(np.uint8(utils.get_printable_image(this_image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Train multi-layer ConvNet with 2 fully connected layers plus output layer\n",
    "\n",
    "For the convolutional layer, we will scan over our images with a certain stride and a certain kernal size. \n",
    "Each individual scan represents a single neuron in the next layer. Since each scan connects to kernal size squared\n",
    "neurons below it, convolutions reduce the number of degrees of freedom. Hopefully, through learning the right filters,\n",
    "we can preserve the important information as we reduce it in size.\n",
    "\n",
    "Once the image has gone through the convolutional layers (and therefore has been reduced to its features vector), we\n",
    "can send the resulting vector into some old-fashioned fully-connected layers, and finally into a logistic regression unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "filters = []\n",
    "kernels = []\n",
    "strides = []\n",
    "pools = []\n",
    "dropouts = []\n",
    "\n",
    "# Conv1\n",
    "filters.append(32)\n",
    "kernels.append(5)\n",
    "strides.append(2)\n",
    "pools.append(2)\n",
    "dropouts.append(0.4)\n",
    "\n",
    "# Conv2\n",
    "filters.append(128)\n",
    "kernels.append(5)\n",
    "strides.append(2)\n",
    "pools.append(2)\n",
    "dropouts.append(0.3)\n",
    "\n",
    "# Conv3\n",
    "filters.append(256)\n",
    "kernels.append(4)\n",
    "strides.append(2)\n",
    "pools.append(2)\n",
    "dropouts.append(0.2)\n",
    "\n",
    "# Define dense (fully-connected) layer sizes\n",
    "fc1 = 40\n",
    "fc2 = 20\n",
    "fc3 = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define keras layers (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_params(input):\n",
    "    a = input[0]\n",
    "    b = input[1]\n",
    "    return concatenate([a,b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layer (RGB image matrix)\n",
    "X = Input(shape=input_shape, name='Input')\n",
    "\n",
    "# Define additional input info\n",
    "Params = Input(shape=(num_params,), name='Params')\n",
    "\n",
    "# Initialize activation as input\n",
    "a = X\n",
    "# Loop through all convolutional layers\n",
    "for i in range(len(filters)):\n",
    "    # Perform convolution\n",
    "    a = Conv2D(filters=filters[i], kernel_size=(kernels[i], kernels[i]), strides=(strides[i], strides[i]), name=('conv' + str(i)))(a)\n",
    "    # Normalize\n",
    "    a = BatchNormalization(axis=3, name=('bn' + str(i)))(a)\n",
    "    # Activate\n",
    "    a = Activation('relu', name=('a' + str(i)))(a)\n",
    "    # Max-pool\n",
    "    a = MaxPooling2D((pools[i], pools[i]), name=('max_pool' + str(i)))(a)\n",
    "    # Dropout\n",
    "    a = Dropout(rate=dropouts[i])(a)\n",
    "\n",
    "# Flatten output of convNet\n",
    "a = Flatten()(a)\n",
    "# Define first fully connected layer\n",
    "a = Dense(units=fc1, activation='relu', name='fc0')(a)\n",
    "# Use some dropout here for regularization\n",
    "a = Dropout(rate=0.3)(a)\n",
    "\n",
    "# Activate parameters\n",
    "a_params = Activation('tanh', name='param_act')(Params)\n",
    "\n",
    "# Concatenate parameters to activations\n",
    "a = Lambda(concat_params, name='concat_params')([a, a_params])\n",
    "\n",
    "# Define second fully connected layer\n",
    "a = Dense(units=fc2, activation='relu', name='fc1')(a)\n",
    "# Use some dropout here for regularization\n",
    "a = Dropout(rate=0.3)(a)\n",
    "# Define second fully connected layer\n",
    "a = Dense(units=fc3, activation='relu', name='fc2')(a)\n",
    "\n",
    "# Define output layer \n",
    "a = Dense(units=1, activation='sigmoid', name='sigmoid')(a)\n",
    "\n",
    "# Make the model\n",
    "model = Model(inputs=[X, Params], outputs=a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define optimizer, loss, and metrics. Compile model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 236, 348, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 116, 172, 32) 2432        Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 116, 172, 32) 128         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "a0 (Activation)                 (None, 116, 172, 32) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)        (None, 58, 86, 32)   0           a0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 58, 86, 32)   0           max_pool0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 27, 41, 128)  102528      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 27, 41, 128)  512         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "a1 (Activation)                 (None, 27, 41, 128)  0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)        (None, 13, 20, 128)  0           a1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 13, 20, 128)  0           max_pool1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 5, 9, 256)    524544      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 5, 9, 256)    1024        conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "a2 (Activation)                 (None, 5, 9, 256)    0           bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)        (None, 2, 4, 256)    0           a2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2, 4, 256)    0           max_pool2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc0 (Dense)                     (None, 40)           81960       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Params (InputLayer)             (None, 54)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 40)           0           fc0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "param_act (Activation)          (None, 54)           0           Params[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_params (Lambda)          (None, 94)           0           dropout_4[0][0]                  \n",
      "                                                                 param_act[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 20)           1900        concat_params[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 20)           0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 20)           420         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid (Dense)                 (None, 1)            21          fc2[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 715,469\n",
      "Trainable params: 714,637\n",
      "Non-trainable params: 832\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer\n",
    "#opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001)\n",
    "opt = SGD(lr=1.0, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Define loss\n",
    "loss = 'mean_squared_error'\n",
    "# Define metrics to use\n",
    "metrics=['acc']\n",
    "# Compile model\n",
    "model.compile(loss=loss, optimizer='sgd', metrics=metrics)\n",
    "# Print summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit the model to the data (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1396 samples, validate on 129 samples\n",
      "Epoch 1/1000\n",
      "1396/1396 [==============================] - 6s 4ms/step - loss: 0.3012 - acc: 0.4721 - val_loss: 0.2666 - val_acc: 0.4031\n",
      "Epoch 2/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2739 - acc: 0.5244 - val_loss: 0.2598 - val_acc: 0.4496\n",
      "Epoch 3/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2679 - acc: 0.5086 - val_loss: 0.2535 - val_acc: 0.4961\n",
      "Epoch 4/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2600 - acc: 0.5337 - val_loss: 0.2515 - val_acc: 0.5116\n",
      "Epoch 5/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2527 - acc: 0.5408 - val_loss: 0.2479 - val_acc: 0.5271\n",
      "Epoch 6/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2564 - acc: 0.5201 - val_loss: 0.2450 - val_acc: 0.5039\n",
      "Epoch 7/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2500 - acc: 0.5473 - val_loss: 0.2365 - val_acc: 0.6202\n",
      "Epoch 8/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2421 - acc: 0.5766 - val_loss: 0.2326 - val_acc: 0.6589\n",
      "Epoch 9/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2413 - acc: 0.5623 - val_loss: 0.2283 - val_acc: 0.6357\n",
      "Epoch 10/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2373 - acc: 0.5824 - val_loss: 0.2266 - val_acc: 0.6744\n",
      "Epoch 11/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2349 - acc: 0.5981 - val_loss: 0.2222 - val_acc: 0.6977\n",
      "Epoch 12/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2333 - acc: 0.5895 - val_loss: 0.2216 - val_acc: 0.6744\n",
      "Epoch 13/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2326 - acc: 0.5917 - val_loss: 0.2201 - val_acc: 0.6899\n",
      "Epoch 14/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2350 - acc: 0.5795 - val_loss: 0.2195 - val_acc: 0.7132\n",
      "Epoch 15/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2275 - acc: 0.5910 - val_loss: 0.2170 - val_acc: 0.6977\n",
      "Epoch 16/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2312 - acc: 0.5881 - val_loss: 0.2168 - val_acc: 0.7054\n",
      "Epoch 17/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2241 - acc: 0.6082 - val_loss: 0.2133 - val_acc: 0.7442\n",
      "Epoch 18/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2285 - acc: 0.6125 - val_loss: 0.2129 - val_acc: 0.7364\n",
      "Epoch 19/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2254 - acc: 0.6010 - val_loss: 0.2117 - val_acc: 0.7442\n",
      "Epoch 20/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2184 - acc: 0.6254 - val_loss: 0.2078 - val_acc: 0.7132\n",
      "Epoch 21/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2209 - acc: 0.6196 - val_loss: 0.2058 - val_acc: 0.7519\n",
      "Epoch 22/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2216 - acc: 0.6139 - val_loss: 0.2049 - val_acc: 0.7364\n",
      "Epoch 23/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2250 - acc: 0.6196 - val_loss: 0.2039 - val_acc: 0.7209\n",
      "Epoch 24/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2223 - acc: 0.6110 - val_loss: 0.2034 - val_acc: 0.7364\n",
      "Epoch 25/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2158 - acc: 0.6268 - val_loss: 0.2003 - val_acc: 0.7519\n",
      "Epoch 26/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2155 - acc: 0.6440 - val_loss: 0.1971 - val_acc: 0.7364\n",
      "Epoch 27/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2137 - acc: 0.6476 - val_loss: 0.1969 - val_acc: 0.7442\n",
      "Epoch 28/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2145 - acc: 0.6268 - val_loss: 0.1964 - val_acc: 0.7287\n",
      "Epoch 29/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2169 - acc: 0.6325 - val_loss: 0.1970 - val_acc: 0.7442\n",
      "Epoch 30/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2118 - acc: 0.6347 - val_loss: 0.1975 - val_acc: 0.7442\n",
      "Epoch 31/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2099 - acc: 0.6612 - val_loss: 0.1950 - val_acc: 0.7519\n",
      "Epoch 32/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2090 - acc: 0.6476 - val_loss: 0.1935 - val_acc: 0.7519\n",
      "Epoch 33/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2138 - acc: 0.6390 - val_loss: 0.1936 - val_acc: 0.7519\n",
      "Epoch 34/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2050 - acc: 0.6426 - val_loss: 0.1902 - val_acc: 0.7519\n",
      "Epoch 35/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2157 - acc: 0.6383 - val_loss: 0.1914 - val_acc: 0.7442\n",
      "Epoch 36/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2050 - acc: 0.6662 - val_loss: 0.1910 - val_acc: 0.7519\n",
      "Epoch 37/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2049 - acc: 0.6669 - val_loss: 0.1900 - val_acc: 0.7519\n",
      "Epoch 38/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2033 - acc: 0.6777 - val_loss: 0.1893 - val_acc: 0.7519\n",
      "Epoch 39/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2061 - acc: 0.6691 - val_loss: 0.1886 - val_acc: 0.7597\n",
      "Epoch 40/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2022 - acc: 0.6526 - val_loss: 0.1890 - val_acc: 0.7597\n",
      "Epoch 41/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2052 - acc: 0.6640 - val_loss: 0.1885 - val_acc: 0.7752\n",
      "Epoch 42/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1996 - acc: 0.6920 - val_loss: 0.1874 - val_acc: 0.7752\n",
      "Epoch 43/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2085 - acc: 0.6511 - val_loss: 0.1881 - val_acc: 0.7674\n",
      "Epoch 44/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1992 - acc: 0.6891 - val_loss: 0.1881 - val_acc: 0.7674\n",
      "Epoch 45/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1952 - acc: 0.6970 - val_loss: 0.1881 - val_acc: 0.7674\n",
      "Epoch 46/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1969 - acc: 0.6884 - val_loss: 0.1856 - val_acc: 0.7674\n",
      "Epoch 47/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1964 - acc: 0.6848 - val_loss: 0.1852 - val_acc: 0.7674\n",
      "Epoch 48/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.2009 - acc: 0.6769 - val_loss: 0.1842 - val_acc: 0.7752\n",
      "Epoch 49/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1943 - acc: 0.6920 - val_loss: 0.1834 - val_acc: 0.7752\n",
      "Epoch 50/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1965 - acc: 0.6963 - val_loss: 0.1843 - val_acc: 0.7752\n",
      "Epoch 51/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1952 - acc: 0.6848 - val_loss: 0.1834 - val_acc: 0.7752\n",
      "Epoch 52/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1925 - acc: 0.6963 - val_loss: 0.1823 - val_acc: 0.7674\n",
      "Epoch 53/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1930 - acc: 0.6970 - val_loss: 0.1829 - val_acc: 0.7674\n",
      "Epoch 54/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1909 - acc: 0.7092 - val_loss: 0.1817 - val_acc: 0.7674\n",
      "Epoch 55/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1935 - acc: 0.6877 - val_loss: 0.1828 - val_acc: 0.7752\n",
      "Epoch 56/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1941 - acc: 0.6913 - val_loss: 0.1801 - val_acc: 0.7674\n",
      "Epoch 57/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1902 - acc: 0.7113 - val_loss: 0.1818 - val_acc: 0.7674\n",
      "Epoch 58/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1923 - acc: 0.7170 - val_loss: 0.1805 - val_acc: 0.7674\n",
      "Epoch 59/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1881 - acc: 0.7199 - val_loss: 0.1798 - val_acc: 0.7674\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1873 - acc: 0.6984 - val_loss: 0.1797 - val_acc: 0.7674\n",
      "Epoch 61/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1902 - acc: 0.7006 - val_loss: 0.1812 - val_acc: 0.7674\n",
      "Epoch 62/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1858 - acc: 0.7185 - val_loss: 0.1803 - val_acc: 0.7597\n",
      "Epoch 63/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1875 - acc: 0.7013 - val_loss: 0.1799 - val_acc: 0.7597\n",
      "Epoch 64/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1870 - acc: 0.7192 - val_loss: 0.1803 - val_acc: 0.7597\n",
      "Epoch 65/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1896 - acc: 0.7063 - val_loss: 0.1795 - val_acc: 0.7597\n",
      "Epoch 66/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1863 - acc: 0.7163 - val_loss: 0.1783 - val_acc: 0.7597\n",
      "Epoch 67/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1790 - acc: 0.7421 - val_loss: 0.1800 - val_acc: 0.7519\n",
      "Epoch 68/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1887 - acc: 0.7056 - val_loss: 0.1802 - val_acc: 0.7519\n",
      "Epoch 69/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1840 - acc: 0.7170 - val_loss: 0.1789 - val_acc: 0.7364\n",
      "Epoch 70/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1810 - acc: 0.7242 - val_loss: 0.1776 - val_acc: 0.7442\n",
      "Epoch 71/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1790 - acc: 0.7242 - val_loss: 0.1786 - val_acc: 0.7364\n",
      "Epoch 72/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1750 - acc: 0.7350 - val_loss: 0.1760 - val_acc: 0.7442\n",
      "Epoch 73/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1804 - acc: 0.7285 - val_loss: 0.1739 - val_acc: 0.7519\n",
      "Epoch 74/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1812 - acc: 0.7213 - val_loss: 0.1731 - val_acc: 0.7597\n",
      "Epoch 75/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1788 - acc: 0.7221 - val_loss: 0.1741 - val_acc: 0.7597\n",
      "Epoch 76/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1780 - acc: 0.7371 - val_loss: 0.1726 - val_acc: 0.7519\n",
      "Epoch 77/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1808 - acc: 0.7285 - val_loss: 0.1728 - val_acc: 0.7519\n",
      "Epoch 78/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1767 - acc: 0.7256 - val_loss: 0.1745 - val_acc: 0.7519\n",
      "Epoch 79/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1756 - acc: 0.7321 - val_loss: 0.1743 - val_acc: 0.7597\n",
      "Epoch 80/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1785 - acc: 0.7292 - val_loss: 0.1729 - val_acc: 0.7519\n",
      "Epoch 81/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1736 - acc: 0.7400 - val_loss: 0.1700 - val_acc: 0.7519\n",
      "Epoch 82/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1783 - acc: 0.7228 - val_loss: 0.1706 - val_acc: 0.7519\n",
      "Epoch 83/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1763 - acc: 0.7350 - val_loss: 0.1714 - val_acc: 0.7442\n",
      "Epoch 84/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1787 - acc: 0.7371 - val_loss: 0.1706 - val_acc: 0.7519\n",
      "Epoch 85/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1746 - acc: 0.7256 - val_loss: 0.1689 - val_acc: 0.7519\n",
      "Epoch 86/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1750 - acc: 0.7364 - val_loss: 0.1674 - val_acc: 0.7519\n",
      "Epoch 87/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1722 - acc: 0.7457 - val_loss: 0.1679 - val_acc: 0.7519\n",
      "Epoch 88/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1754 - acc: 0.7400 - val_loss: 0.1694 - val_acc: 0.7519\n",
      "Epoch 89/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1719 - acc: 0.7443 - val_loss: 0.1685 - val_acc: 0.7442\n",
      "Epoch 90/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1740 - acc: 0.7414 - val_loss: 0.1684 - val_acc: 0.7519\n",
      "Epoch 91/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1685 - acc: 0.7564 - val_loss: 0.1698 - val_acc: 0.7287\n",
      "Epoch 92/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1699 - acc: 0.7464 - val_loss: 0.1695 - val_acc: 0.7209\n",
      "Epoch 93/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1643 - acc: 0.7600 - val_loss: 0.1696 - val_acc: 0.7364\n",
      "Epoch 94/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1701 - acc: 0.7443 - val_loss: 0.1661 - val_acc: 0.7364\n",
      "Epoch 95/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1701 - acc: 0.7443 - val_loss: 0.1650 - val_acc: 0.7364\n",
      "Epoch 96/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1676 - acc: 0.7550 - val_loss: 0.1654 - val_acc: 0.7364\n",
      "Epoch 97/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1690 - acc: 0.7486 - val_loss: 0.1652 - val_acc: 0.7364\n",
      "Epoch 98/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1668 - acc: 0.7450 - val_loss: 0.1653 - val_acc: 0.7442\n",
      "Epoch 99/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1668 - acc: 0.7586 - val_loss: 0.1636 - val_acc: 0.7442\n",
      "Epoch 100/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1679 - acc: 0.7378 - val_loss: 0.1651 - val_acc: 0.7364\n",
      "Epoch 101/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1638 - acc: 0.7550 - val_loss: 0.1622 - val_acc: 0.7442\n",
      "Epoch 102/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1661 - acc: 0.7543 - val_loss: 0.1605 - val_acc: 0.7442\n",
      "Epoch 103/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1630 - acc: 0.7543 - val_loss: 0.1610 - val_acc: 0.7442\n",
      "Epoch 104/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1624 - acc: 0.7643 - val_loss: 0.1616 - val_acc: 0.7442\n",
      "Epoch 105/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1641 - acc: 0.7529 - val_loss: 0.1619 - val_acc: 0.7442\n",
      "Epoch 106/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1665 - acc: 0.7450 - val_loss: 0.1632 - val_acc: 0.7364\n",
      "Epoch 107/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1618 - acc: 0.7665 - val_loss: 0.1625 - val_acc: 0.7364\n",
      "Epoch 108/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1556 - acc: 0.7815 - val_loss: 0.1610 - val_acc: 0.7364\n",
      "Epoch 109/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1623 - acc: 0.7622 - val_loss: 0.1630 - val_acc: 0.7364\n",
      "Epoch 110/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1627 - acc: 0.7550 - val_loss: 0.1630 - val_acc: 0.7364\n",
      "Epoch 111/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1588 - acc: 0.7686 - val_loss: 0.1631 - val_acc: 0.7364\n",
      "Epoch 112/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1587 - acc: 0.7600 - val_loss: 0.1621 - val_acc: 0.7364\n",
      "Epoch 113/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1556 - acc: 0.7779 - val_loss: 0.1618 - val_acc: 0.7287\n",
      "Epoch 114/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1552 - acc: 0.7765 - val_loss: 0.1609 - val_acc: 0.7442\n",
      "Epoch 115/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1514 - acc: 0.7901 - val_loss: 0.1568 - val_acc: 0.7597\n",
      "Epoch 116/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1588 - acc: 0.7615 - val_loss: 0.1599 - val_acc: 0.7364\n",
      "Epoch 117/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1552 - acc: 0.7736 - val_loss: 0.1579 - val_acc: 0.7597\n",
      "Epoch 118/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1539 - acc: 0.7679 - val_loss: 0.1632 - val_acc: 0.7364\n",
      "Epoch 119/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1516 - acc: 0.7851 - val_loss: 0.1598 - val_acc: 0.7442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1565 - acc: 0.7729 - val_loss: 0.1589 - val_acc: 0.7519\n",
      "Epoch 121/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1518 - acc: 0.7765 - val_loss: 0.1581 - val_acc: 0.7597\n",
      "Epoch 122/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1534 - acc: 0.7758 - val_loss: 0.1593 - val_acc: 0.7597\n",
      "Epoch 123/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1560 - acc: 0.7679 - val_loss: 0.1597 - val_acc: 0.7597\n",
      "Epoch 124/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1520 - acc: 0.7880 - val_loss: 0.1585 - val_acc: 0.7519\n",
      "Epoch 125/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1526 - acc: 0.7708 - val_loss: 0.1588 - val_acc: 0.7519\n",
      "Epoch 126/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1483 - acc: 0.7923 - val_loss: 0.1574 - val_acc: 0.7597\n",
      "Epoch 127/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1493 - acc: 0.7872 - val_loss: 0.1590 - val_acc: 0.7519\n",
      "Epoch 128/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1448 - acc: 0.7872 - val_loss: 0.1576 - val_acc: 0.7519\n",
      "Epoch 129/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1490 - acc: 0.7772 - val_loss: 0.1580 - val_acc: 0.7519\n",
      "Epoch 130/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1470 - acc: 0.7880 - val_loss: 0.1588 - val_acc: 0.7287\n",
      "Epoch 131/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1495 - acc: 0.7844 - val_loss: 0.1584 - val_acc: 0.7364\n",
      "Epoch 132/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1487 - acc: 0.7865 - val_loss: 0.1603 - val_acc: 0.7442\n",
      "Epoch 133/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1448 - acc: 0.7973 - val_loss: 0.1566 - val_acc: 0.7442\n",
      "Epoch 134/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1481 - acc: 0.7858 - val_loss: 0.1553 - val_acc: 0.7519\n",
      "Epoch 135/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1443 - acc: 0.7951 - val_loss: 0.1576 - val_acc: 0.7442\n",
      "Epoch 136/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1541 - acc: 0.7722 - val_loss: 0.1585 - val_acc: 0.7442\n",
      "Epoch 137/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1428 - acc: 0.7951 - val_loss: 0.1575 - val_acc: 0.7519\n",
      "Epoch 138/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1434 - acc: 0.7901 - val_loss: 0.1551 - val_acc: 0.7519\n",
      "Epoch 139/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1471 - acc: 0.7865 - val_loss: 0.1548 - val_acc: 0.7519\n",
      "Epoch 140/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1454 - acc: 0.7958 - val_loss: 0.1536 - val_acc: 0.7519\n",
      "Epoch 141/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1386 - acc: 0.8052 - val_loss: 0.1522 - val_acc: 0.7442\n",
      "Epoch 142/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1411 - acc: 0.8059 - val_loss: 0.1554 - val_acc: 0.7519\n",
      "Epoch 143/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1440 - acc: 0.7951 - val_loss: 0.1542 - val_acc: 0.7442\n",
      "Epoch 144/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1465 - acc: 0.7851 - val_loss: 0.1565 - val_acc: 0.7519\n",
      "Epoch 145/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1390 - acc: 0.8001 - val_loss: 0.1562 - val_acc: 0.7519\n",
      "Epoch 146/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1360 - acc: 0.8023 - val_loss: 0.1565 - val_acc: 0.7442\n",
      "Epoch 147/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1354 - acc: 0.8073 - val_loss: 0.1533 - val_acc: 0.7519\n",
      "Epoch 148/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1424 - acc: 0.7923 - val_loss: 0.1555 - val_acc: 0.7442\n",
      "Epoch 149/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1410 - acc: 0.7930 - val_loss: 0.1549 - val_acc: 0.7597\n",
      "Epoch 150/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1420 - acc: 0.8016 - val_loss: 0.1544 - val_acc: 0.7519\n",
      "Epoch 151/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1342 - acc: 0.8181 - val_loss: 0.1598 - val_acc: 0.7442\n",
      "Epoch 152/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1384 - acc: 0.7987 - val_loss: 0.1558 - val_acc: 0.7364\n",
      "Epoch 153/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1352 - acc: 0.8130 - val_loss: 0.1590 - val_acc: 0.7287\n",
      "Epoch 154/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1356 - acc: 0.8044 - val_loss: 0.1601 - val_acc: 0.7287\n",
      "Epoch 155/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1338 - acc: 0.8188 - val_loss: 0.1572 - val_acc: 0.7519\n",
      "Epoch 156/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1379 - acc: 0.8044 - val_loss: 0.1557 - val_acc: 0.7519\n",
      "Epoch 157/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1311 - acc: 0.8188 - val_loss: 0.1544 - val_acc: 0.7519\n",
      "Epoch 158/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1312 - acc: 0.8130 - val_loss: 0.1532 - val_acc: 0.7519\n",
      "Epoch 159/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1349 - acc: 0.8152 - val_loss: 0.1522 - val_acc: 0.7519\n",
      "Epoch 160/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1388 - acc: 0.8073 - val_loss: 0.1499 - val_acc: 0.7752\n",
      "Epoch 161/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1337 - acc: 0.8116 - val_loss: 0.1613 - val_acc: 0.7132\n",
      "Epoch 162/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1348 - acc: 0.8130 - val_loss: 0.1652 - val_acc: 0.7132\n",
      "Epoch 163/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1318 - acc: 0.8123 - val_loss: 0.1621 - val_acc: 0.7287\n",
      "Epoch 164/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1304 - acc: 0.8195 - val_loss: 0.1615 - val_acc: 0.7132\n",
      "Epoch 165/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1315 - acc: 0.8159 - val_loss: 0.1607 - val_acc: 0.7209\n",
      "Epoch 166/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1287 - acc: 0.8138 - val_loss: 0.1622 - val_acc: 0.7287\n",
      "Epoch 167/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1298 - acc: 0.8145 - val_loss: 0.1635 - val_acc: 0.7287\n",
      "Epoch 168/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1278 - acc: 0.8145 - val_loss: 0.1609 - val_acc: 0.7519\n",
      "Epoch 169/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1281 - acc: 0.8231 - val_loss: 0.1649 - val_acc: 0.7209\n",
      "Epoch 170/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1288 - acc: 0.8245 - val_loss: 0.1627 - val_acc: 0.7209\n",
      "Epoch 171/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1292 - acc: 0.8080 - val_loss: 0.1637 - val_acc: 0.7132\n",
      "Epoch 172/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1303 - acc: 0.8166 - val_loss: 0.1618 - val_acc: 0.7287\n",
      "Epoch 173/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1273 - acc: 0.8231 - val_loss: 0.1630 - val_acc: 0.7209\n",
      "Epoch 174/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1273 - acc: 0.8309 - val_loss: 0.1683 - val_acc: 0.7054\n",
      "Epoch 175/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1227 - acc: 0.8281 - val_loss: 0.1614 - val_acc: 0.7287\n",
      "Epoch 176/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1214 - acc: 0.8281 - val_loss: 0.1557 - val_acc: 0.7519\n",
      "Epoch 177/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1305 - acc: 0.8116 - val_loss: 0.1615 - val_acc: 0.7132\n",
      "Epoch 178/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1215 - acc: 0.8352 - val_loss: 0.1616 - val_acc: 0.7132\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1235 - acc: 0.8223 - val_loss: 0.1589 - val_acc: 0.7287\n",
      "Epoch 180/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1282 - acc: 0.8209 - val_loss: 0.1578 - val_acc: 0.7442\n",
      "Epoch 181/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1228 - acc: 0.8338 - val_loss: 0.1564 - val_acc: 0.7519\n",
      "Epoch 182/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1237 - acc: 0.8238 - val_loss: 0.1595 - val_acc: 0.7442\n",
      "Epoch 183/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1218 - acc: 0.8360 - val_loss: 0.1592 - val_acc: 0.7442\n",
      "Epoch 184/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1269 - acc: 0.8109 - val_loss: 0.1609 - val_acc: 0.7287\n",
      "Epoch 185/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1238 - acc: 0.8274 - val_loss: 0.1596 - val_acc: 0.7442\n",
      "Epoch 186/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1215 - acc: 0.8252 - val_loss: 0.1607 - val_acc: 0.7287\n",
      "Epoch 187/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1207 - acc: 0.8352 - val_loss: 0.1648 - val_acc: 0.6977\n",
      "Epoch 188/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1212 - acc: 0.8302 - val_loss: 0.1597 - val_acc: 0.7364\n",
      "Epoch 189/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1256 - acc: 0.8331 - val_loss: 0.1645 - val_acc: 0.7054\n",
      "Epoch 190/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1236 - acc: 0.8345 - val_loss: 0.1611 - val_acc: 0.7132\n",
      "Epoch 191/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1222 - acc: 0.8403 - val_loss: 0.1599 - val_acc: 0.7442\n",
      "Epoch 192/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1200 - acc: 0.8403 - val_loss: 0.1669 - val_acc: 0.7054\n",
      "Epoch 193/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1158 - acc: 0.8431 - val_loss: 0.1596 - val_acc: 0.7364\n",
      "Epoch 194/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1233 - acc: 0.8259 - val_loss: 0.1666 - val_acc: 0.7054\n",
      "Epoch 195/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1164 - acc: 0.8352 - val_loss: 0.1704 - val_acc: 0.7054\n",
      "Epoch 196/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1183 - acc: 0.8374 - val_loss: 0.1677 - val_acc: 0.7054\n",
      "Epoch 197/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1199 - acc: 0.8317 - val_loss: 0.1653 - val_acc: 0.7054\n",
      "Epoch 198/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1136 - acc: 0.8388 - val_loss: 0.1620 - val_acc: 0.7209\n",
      "Epoch 199/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1206 - acc: 0.8324 - val_loss: 0.1694 - val_acc: 0.6977\n",
      "Epoch 200/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1155 - acc: 0.8331 - val_loss: 0.1681 - val_acc: 0.6977\n",
      "Epoch 201/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1138 - acc: 0.8438 - val_loss: 0.1613 - val_acc: 0.7442\n",
      "Epoch 202/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1195 - acc: 0.8352 - val_loss: 0.1640 - val_acc: 0.7364\n",
      "Epoch 203/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1159 - acc: 0.8424 - val_loss: 0.1655 - val_acc: 0.7209\n",
      "Epoch 204/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1142 - acc: 0.8424 - val_loss: 0.1656 - val_acc: 0.7209\n",
      "Epoch 205/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1154 - acc: 0.8345 - val_loss: 0.1701 - val_acc: 0.6899\n",
      "Epoch 206/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1091 - acc: 0.8610 - val_loss: 0.1679 - val_acc: 0.7132\n",
      "Epoch 207/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1106 - acc: 0.8496 - val_loss: 0.1693 - val_acc: 0.6899\n",
      "Epoch 208/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1076 - acc: 0.8489 - val_loss: 0.1668 - val_acc: 0.7132\n",
      "Epoch 209/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1094 - acc: 0.8510 - val_loss: 0.1670 - val_acc: 0.7287\n",
      "Epoch 210/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1187 - acc: 0.8281 - val_loss: 0.1647 - val_acc: 0.7287\n",
      "Epoch 211/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1101 - acc: 0.8589 - val_loss: 0.1582 - val_acc: 0.7364\n",
      "Epoch 212/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1124 - acc: 0.8524 - val_loss: 0.1630 - val_acc: 0.7209\n",
      "Epoch 213/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1153 - acc: 0.8431 - val_loss: 0.1596 - val_acc: 0.7519\n",
      "Epoch 214/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1104 - acc: 0.8532 - val_loss: 0.1617 - val_acc: 0.7364\n",
      "Epoch 215/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1057 - acc: 0.8553 - val_loss: 0.1652 - val_acc: 0.7209\n",
      "Epoch 216/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1082 - acc: 0.8560 - val_loss: 0.1615 - val_acc: 0.7364\n",
      "Epoch 217/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1056 - acc: 0.8560 - val_loss: 0.1690 - val_acc: 0.7209\n",
      "Epoch 218/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1073 - acc: 0.8546 - val_loss: 0.1659 - val_acc: 0.7209\n",
      "Epoch 219/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1093 - acc: 0.8574 - val_loss: 0.1607 - val_acc: 0.7287\n",
      "Epoch 220/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1010 - acc: 0.8682 - val_loss: 0.1687 - val_acc: 0.7132\n",
      "Epoch 221/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1009 - acc: 0.8725 - val_loss: 0.1665 - val_acc: 0.7132\n",
      "Epoch 222/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1094 - acc: 0.8510 - val_loss: 0.1605 - val_acc: 0.7442\n",
      "Epoch 223/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1047 - acc: 0.8653 - val_loss: 0.1669 - val_acc: 0.7209\n",
      "Epoch 224/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1048 - acc: 0.8639 - val_loss: 0.1750 - val_acc: 0.6899\n",
      "Epoch 225/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1013 - acc: 0.8703 - val_loss: 0.1676 - val_acc: 0.7209\n",
      "Epoch 226/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1053 - acc: 0.8582 - val_loss: 0.1652 - val_acc: 0.7287\n",
      "Epoch 227/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1001 - acc: 0.8682 - val_loss: 0.1655 - val_acc: 0.7209\n",
      "Epoch 228/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1045 - acc: 0.8532 - val_loss: 0.1652 - val_acc: 0.7209\n",
      "Epoch 229/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1104 - acc: 0.8496 - val_loss: 0.1779 - val_acc: 0.7054\n",
      "Epoch 230/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1069 - acc: 0.8553 - val_loss: 0.1704 - val_acc: 0.7132\n",
      "Epoch 231/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1047 - acc: 0.8610 - val_loss: 0.1710 - val_acc: 0.7132\n",
      "Epoch 232/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1029 - acc: 0.8646 - val_loss: 0.1700 - val_acc: 0.7054\n",
      "Epoch 233/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1078 - acc: 0.8417 - val_loss: 0.1713 - val_acc: 0.7054\n",
      "Epoch 234/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1009 - acc: 0.8603 - val_loss: 0.1809 - val_acc: 0.6667\n",
      "Epoch 235/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1035 - acc: 0.8610 - val_loss: 0.1617 - val_acc: 0.7364\n",
      "Epoch 236/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1040 - acc: 0.8603 - val_loss: 0.1649 - val_acc: 0.7364\n",
      "Epoch 237/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0965 - acc: 0.8782 - val_loss: 0.1660 - val_acc: 0.7132\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1003 - acc: 0.8646 - val_loss: 0.1624 - val_acc: 0.7519\n",
      "Epoch 239/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1064 - acc: 0.8517 - val_loss: 0.1650 - val_acc: 0.7209\n",
      "Epoch 240/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0946 - acc: 0.8725 - val_loss: 0.1596 - val_acc: 0.7442\n",
      "Epoch 241/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1018 - acc: 0.8625 - val_loss: 0.1622 - val_acc: 0.7442\n",
      "Epoch 242/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0964 - acc: 0.8804 - val_loss: 0.1670 - val_acc: 0.7287\n",
      "Epoch 243/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1049 - acc: 0.8582 - val_loss: 0.1638 - val_acc: 0.7364\n",
      "Epoch 244/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0977 - acc: 0.8696 - val_loss: 0.1750 - val_acc: 0.7054\n",
      "Epoch 245/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0971 - acc: 0.8746 - val_loss: 0.1696 - val_acc: 0.7209\n",
      "Epoch 246/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0992 - acc: 0.8675 - val_loss: 0.1705 - val_acc: 0.7054\n",
      "Epoch 247/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1000 - acc: 0.8646 - val_loss: 0.1702 - val_acc: 0.7054\n",
      "Epoch 248/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0970 - acc: 0.8682 - val_loss: 0.1747 - val_acc: 0.7054\n",
      "Epoch 249/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1037 - acc: 0.8567 - val_loss: 0.1716 - val_acc: 0.7054\n",
      "Epoch 250/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1008 - acc: 0.8639 - val_loss: 0.1741 - val_acc: 0.7054\n",
      "Epoch 251/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1043 - acc: 0.8474 - val_loss: 0.1746 - val_acc: 0.7054\n",
      "Epoch 252/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1015 - acc: 0.8603 - val_loss: 0.1733 - val_acc: 0.6977\n",
      "Epoch 253/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.1069 - acc: 0.8582 - val_loss: 0.1708 - val_acc: 0.6977\n",
      "Epoch 254/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0987 - acc: 0.8682 - val_loss: 0.1662 - val_acc: 0.7132\n",
      "Epoch 255/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0996 - acc: 0.8646 - val_loss: 0.1632 - val_acc: 0.7364\n",
      "Epoch 256/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0929 - acc: 0.8782 - val_loss: 0.1721 - val_acc: 0.7054\n",
      "Epoch 257/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0949 - acc: 0.8675 - val_loss: 0.1686 - val_acc: 0.7209\n",
      "Epoch 258/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0983 - acc: 0.8646 - val_loss: 0.1712 - val_acc: 0.7209\n",
      "Epoch 259/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0944 - acc: 0.8789 - val_loss: 0.1736 - val_acc: 0.6822\n",
      "Epoch 260/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0984 - acc: 0.8675 - val_loss: 0.1747 - val_acc: 0.6744\n",
      "Epoch 261/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0932 - acc: 0.8804 - val_loss: 0.1658 - val_acc: 0.7364\n",
      "Epoch 262/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0951 - acc: 0.8696 - val_loss: 0.1646 - val_acc: 0.7209\n",
      "Epoch 263/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0951 - acc: 0.8660 - val_loss: 0.1606 - val_acc: 0.7442\n",
      "Epoch 264/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0937 - acc: 0.8775 - val_loss: 0.1602 - val_acc: 0.7442\n",
      "Epoch 265/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0966 - acc: 0.8696 - val_loss: 0.1654 - val_acc: 0.7287\n",
      "Epoch 266/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0982 - acc: 0.8632 - val_loss: 0.1767 - val_acc: 0.6899\n",
      "Epoch 267/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0956 - acc: 0.8675 - val_loss: 0.1650 - val_acc: 0.7364\n",
      "Epoch 268/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0927 - acc: 0.8746 - val_loss: 0.1649 - val_acc: 0.7364\n",
      "Epoch 269/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0887 - acc: 0.8890 - val_loss: 0.1747 - val_acc: 0.6899\n",
      "Epoch 270/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0944 - acc: 0.8732 - val_loss: 0.1726 - val_acc: 0.6977\n",
      "Epoch 271/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0902 - acc: 0.8718 - val_loss: 0.1744 - val_acc: 0.6899\n",
      "Epoch 272/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0963 - acc: 0.8646 - val_loss: 0.1729 - val_acc: 0.6899\n",
      "Epoch 273/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0918 - acc: 0.8711 - val_loss: 0.1708 - val_acc: 0.7054\n",
      "Epoch 274/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0915 - acc: 0.8754 - val_loss: 0.1732 - val_acc: 0.6977\n",
      "Epoch 275/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0940 - acc: 0.8689 - val_loss: 0.1765 - val_acc: 0.6977\n",
      "Epoch 276/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0952 - acc: 0.8725 - val_loss: 0.1798 - val_acc: 0.6977\n",
      "Epoch 277/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0908 - acc: 0.8797 - val_loss: 0.1773 - val_acc: 0.6977\n",
      "Epoch 278/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0946 - acc: 0.8718 - val_loss: 0.1763 - val_acc: 0.7054\n",
      "Epoch 279/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0907 - acc: 0.8703 - val_loss: 0.1830 - val_acc: 0.6977\n",
      "Epoch 280/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0974 - acc: 0.8639 - val_loss: 0.1893 - val_acc: 0.6744\n",
      "Epoch 281/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0915 - acc: 0.8825 - val_loss: 0.1776 - val_acc: 0.6977\n",
      "Epoch 282/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0920 - acc: 0.8818 - val_loss: 0.1767 - val_acc: 0.7054\n",
      "Epoch 283/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0918 - acc: 0.8804 - val_loss: 0.1775 - val_acc: 0.6899\n",
      "Epoch 284/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0923 - acc: 0.8768 - val_loss: 0.1835 - val_acc: 0.6744\n",
      "Epoch 285/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0958 - acc: 0.8668 - val_loss: 0.1802 - val_acc: 0.6822\n",
      "Epoch 286/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0916 - acc: 0.8739 - val_loss: 0.1655 - val_acc: 0.7287\n",
      "Epoch 287/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0905 - acc: 0.8782 - val_loss: 0.1733 - val_acc: 0.6977\n",
      "Epoch 288/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0900 - acc: 0.8832 - val_loss: 0.1713 - val_acc: 0.6977\n",
      "Epoch 289/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0888 - acc: 0.8825 - val_loss: 0.1636 - val_acc: 0.7287\n",
      "Epoch 290/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0859 - acc: 0.8883 - val_loss: 0.1634 - val_acc: 0.7364\n",
      "Epoch 291/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0889 - acc: 0.8847 - val_loss: 0.1589 - val_acc: 0.7364\n",
      "Epoch 292/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0855 - acc: 0.8883 - val_loss: 0.1573 - val_acc: 0.7597\n",
      "Epoch 293/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0883 - acc: 0.8875 - val_loss: 0.1657 - val_acc: 0.7364\n",
      "Epoch 294/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0919 - acc: 0.8811 - val_loss: 0.1671 - val_acc: 0.7209\n",
      "Epoch 295/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0872 - acc: 0.8861 - val_loss: 0.1694 - val_acc: 0.6977\n",
      "Epoch 296/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0897 - acc: 0.8797 - val_loss: 0.1718 - val_acc: 0.6977\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0927 - acc: 0.8761 - val_loss: 0.1641 - val_acc: 0.7209\n",
      "Epoch 298/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0883 - acc: 0.8818 - val_loss: 0.1775 - val_acc: 0.6977\n",
      "Epoch 299/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0967 - acc: 0.8653 - val_loss: 0.1776 - val_acc: 0.6899\n",
      "Epoch 300/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0817 - acc: 0.8883 - val_loss: 0.1789 - val_acc: 0.6977\n",
      "Epoch 301/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0822 - acc: 0.8961 - val_loss: 0.1735 - val_acc: 0.7054\n",
      "Epoch 302/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0849 - acc: 0.8926 - val_loss: 0.1702 - val_acc: 0.7132\n",
      "Epoch 303/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0826 - acc: 0.8940 - val_loss: 0.1734 - val_acc: 0.7209\n",
      "Epoch 304/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0845 - acc: 0.8897 - val_loss: 0.1782 - val_acc: 0.6977\n",
      "Epoch 305/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0865 - acc: 0.8818 - val_loss: 0.1730 - val_acc: 0.7132\n",
      "Epoch 306/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0822 - acc: 0.8918 - val_loss: 0.1655 - val_acc: 0.7209\n",
      "Epoch 307/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0790 - acc: 0.9054 - val_loss: 0.1659 - val_acc: 0.7132\n",
      "Epoch 308/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0862 - acc: 0.8840 - val_loss: 0.1751 - val_acc: 0.7054\n",
      "Epoch 309/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0849 - acc: 0.8890 - val_loss: 0.1619 - val_acc: 0.7442\n",
      "Epoch 310/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0809 - acc: 0.8926 - val_loss: 0.1705 - val_acc: 0.7209\n",
      "Epoch 311/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0806 - acc: 0.8961 - val_loss: 0.1768 - val_acc: 0.7054\n",
      "Epoch 312/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0801 - acc: 0.8983 - val_loss: 0.1782 - val_acc: 0.7054\n",
      "Epoch 313/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0806 - acc: 0.8918 - val_loss: 0.1717 - val_acc: 0.7132\n",
      "Epoch 314/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0793 - acc: 0.8983 - val_loss: 0.1756 - val_acc: 0.7054\n",
      "Epoch 315/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0911 - acc: 0.8789 - val_loss: 0.1737 - val_acc: 0.7132\n",
      "Epoch 316/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0804 - acc: 0.8954 - val_loss: 0.1742 - val_acc: 0.7054\n",
      "Epoch 317/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0821 - acc: 0.8940 - val_loss: 0.1774 - val_acc: 0.7054\n",
      "Epoch 318/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0859 - acc: 0.8911 - val_loss: 0.1779 - val_acc: 0.7132\n",
      "Epoch 319/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0854 - acc: 0.8897 - val_loss: 0.1748 - val_acc: 0.7054\n",
      "Epoch 320/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0827 - acc: 0.8890 - val_loss: 0.1753 - val_acc: 0.7209\n",
      "Epoch 321/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0788 - acc: 0.8926 - val_loss: 0.1790 - val_acc: 0.6977\n",
      "Epoch 322/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0835 - acc: 0.8861 - val_loss: 0.1731 - val_acc: 0.7209\n",
      "Epoch 323/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0805 - acc: 0.8961 - val_loss: 0.1758 - val_acc: 0.7132\n",
      "Epoch 324/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0799 - acc: 0.8911 - val_loss: 0.1784 - val_acc: 0.6977\n",
      "Epoch 325/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0803 - acc: 0.8997 - val_loss: 0.1788 - val_acc: 0.6899\n",
      "Epoch 326/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0775 - acc: 0.9062 - val_loss: 0.1807 - val_acc: 0.6977\n",
      "Epoch 327/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0809 - acc: 0.8875 - val_loss: 0.1693 - val_acc: 0.7132\n",
      "Epoch 328/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0863 - acc: 0.8811 - val_loss: 0.1771 - val_acc: 0.6977\n",
      "Epoch 329/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0780 - acc: 0.9011 - val_loss: 0.1685 - val_acc: 0.7132\n",
      "Epoch 330/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0744 - acc: 0.9062 - val_loss: 0.1704 - val_acc: 0.7209\n",
      "Epoch 331/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0805 - acc: 0.8940 - val_loss: 0.1689 - val_acc: 0.7209\n",
      "Epoch 332/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0796 - acc: 0.8954 - val_loss: 0.1696 - val_acc: 0.7209\n",
      "Epoch 333/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0801 - acc: 0.8976 - val_loss: 0.1734 - val_acc: 0.6899\n",
      "Epoch 334/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0875 - acc: 0.8789 - val_loss: 0.1599 - val_acc: 0.7209\n",
      "Epoch 335/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0776 - acc: 0.8990 - val_loss: 0.1640 - val_acc: 0.7132\n",
      "Epoch 336/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0806 - acc: 0.8968 - val_loss: 0.1646 - val_acc: 0.7287\n",
      "Epoch 337/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0818 - acc: 0.8904 - val_loss: 0.1716 - val_acc: 0.7132\n",
      "Epoch 338/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0774 - acc: 0.8968 - val_loss: 0.1592 - val_acc: 0.7364\n",
      "Epoch 339/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0774 - acc: 0.9026 - val_loss: 0.1539 - val_acc: 0.7597\n",
      "Epoch 340/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0678 - acc: 0.9126 - val_loss: 0.1697 - val_acc: 0.7209\n",
      "Epoch 341/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0726 - acc: 0.9076 - val_loss: 0.1727 - val_acc: 0.7132\n",
      "Epoch 342/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0767 - acc: 0.8990 - val_loss: 0.1672 - val_acc: 0.7132\n",
      "Epoch 343/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0796 - acc: 0.9026 - val_loss: 0.1839 - val_acc: 0.6744\n",
      "Epoch 344/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0773 - acc: 0.9026 - val_loss: 0.1671 - val_acc: 0.7287\n",
      "Epoch 345/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0749 - acc: 0.9011 - val_loss: 0.1659 - val_acc: 0.7287\n",
      "Epoch 346/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0749 - acc: 0.9062 - val_loss: 0.1807 - val_acc: 0.6822\n",
      "Epoch 347/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0732 - acc: 0.9033 - val_loss: 0.1855 - val_acc: 0.6899\n",
      "Epoch 348/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0728 - acc: 0.9047 - val_loss: 0.1693 - val_acc: 0.7132\n",
      "Epoch 349/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0766 - acc: 0.8968 - val_loss: 0.1807 - val_acc: 0.6899\n",
      "Epoch 350/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0731 - acc: 0.9062 - val_loss: 0.1677 - val_acc: 0.7287\n",
      "Epoch 351/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0782 - acc: 0.8940 - val_loss: 0.1873 - val_acc: 0.6667\n",
      "Epoch 352/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0749 - acc: 0.9069 - val_loss: 0.1666 - val_acc: 0.7209\n",
      "Epoch 353/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0709 - acc: 0.9162 - val_loss: 0.1723 - val_acc: 0.7054\n",
      "Epoch 354/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0755 - acc: 0.9011 - val_loss: 0.1691 - val_acc: 0.7132\n",
      "Epoch 355/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0735 - acc: 0.9112 - val_loss: 0.1729 - val_acc: 0.6977\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0790 - acc: 0.8897 - val_loss: 0.1684 - val_acc: 0.7287\n",
      "Epoch 357/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0754 - acc: 0.9033 - val_loss: 0.1713 - val_acc: 0.7132\n",
      "Epoch 358/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0731 - acc: 0.8976 - val_loss: 0.1810 - val_acc: 0.6822\n",
      "Epoch 359/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0709 - acc: 0.9090 - val_loss: 0.1738 - val_acc: 0.6977\n",
      "Epoch 360/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0742 - acc: 0.8983 - val_loss: 0.1775 - val_acc: 0.6822\n",
      "Epoch 361/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0725 - acc: 0.8997 - val_loss: 0.1826 - val_acc: 0.6822\n",
      "Epoch 362/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0721 - acc: 0.9062 - val_loss: 0.1715 - val_acc: 0.7132\n",
      "Epoch 363/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0747 - acc: 0.8976 - val_loss: 0.1722 - val_acc: 0.7209\n",
      "Epoch 364/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0780 - acc: 0.8911 - val_loss: 0.1681 - val_acc: 0.7287\n",
      "Epoch 365/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0796 - acc: 0.8954 - val_loss: 0.1772 - val_acc: 0.6977\n",
      "Epoch 366/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0695 - acc: 0.9054 - val_loss: 0.1773 - val_acc: 0.6977\n",
      "Epoch 367/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0766 - acc: 0.8976 - val_loss: 0.1722 - val_acc: 0.7132\n",
      "Epoch 368/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0734 - acc: 0.9062 - val_loss: 0.1726 - val_acc: 0.7132\n",
      "Epoch 369/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0768 - acc: 0.8983 - val_loss: 0.1722 - val_acc: 0.7132\n",
      "Epoch 370/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0705 - acc: 0.9083 - val_loss: 0.1798 - val_acc: 0.6744\n",
      "Epoch 371/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0698 - acc: 0.9162 - val_loss: 0.1739 - val_acc: 0.7132\n",
      "Epoch 372/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0745 - acc: 0.9040 - val_loss: 0.1654 - val_acc: 0.7287\n",
      "Epoch 373/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0727 - acc: 0.9004 - val_loss: 0.1716 - val_acc: 0.7054\n",
      "Epoch 374/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0714 - acc: 0.9090 - val_loss: 0.1714 - val_acc: 0.7132\n",
      "Epoch 375/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0719 - acc: 0.9097 - val_loss: 0.1724 - val_acc: 0.7132\n",
      "Epoch 376/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0691 - acc: 0.9126 - val_loss: 0.1826 - val_acc: 0.6744\n",
      "Epoch 377/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0741 - acc: 0.9090 - val_loss: 0.1784 - val_acc: 0.6899\n",
      "Epoch 378/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0720 - acc: 0.9126 - val_loss: 0.1929 - val_acc: 0.6822\n",
      "Epoch 379/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0684 - acc: 0.9083 - val_loss: 0.1827 - val_acc: 0.6744\n",
      "Epoch 380/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0688 - acc: 0.9162 - val_loss: 0.1880 - val_acc: 0.6744\n",
      "Epoch 381/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0710 - acc: 0.9062 - val_loss: 0.1763 - val_acc: 0.6977\n",
      "Epoch 382/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0699 - acc: 0.9097 - val_loss: 0.1893 - val_acc: 0.6977\n",
      "Epoch 383/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0654 - acc: 0.9126 - val_loss: 0.1813 - val_acc: 0.6977\n",
      "Epoch 384/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0695 - acc: 0.9076 - val_loss: 0.1759 - val_acc: 0.7054\n",
      "Epoch 385/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0725 - acc: 0.9083 - val_loss: 0.1763 - val_acc: 0.7054\n",
      "Epoch 386/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0747 - acc: 0.9011 - val_loss: 0.1749 - val_acc: 0.7132\n",
      "Epoch 387/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0682 - acc: 0.9155 - val_loss: 0.1760 - val_acc: 0.7132\n",
      "Epoch 388/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0706 - acc: 0.9126 - val_loss: 0.1910 - val_acc: 0.6744\n",
      "Epoch 389/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0666 - acc: 0.9183 - val_loss: 0.1765 - val_acc: 0.7054\n",
      "Epoch 390/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0681 - acc: 0.9191 - val_loss: 0.1670 - val_acc: 0.7287\n",
      "Epoch 391/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0687 - acc: 0.9126 - val_loss: 0.1719 - val_acc: 0.7132\n",
      "Epoch 392/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0690 - acc: 0.9148 - val_loss: 0.1643 - val_acc: 0.7364\n",
      "Epoch 393/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0715 - acc: 0.9004 - val_loss: 0.1733 - val_acc: 0.6977\n",
      "Epoch 394/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0705 - acc: 0.9069 - val_loss: 0.1648 - val_acc: 0.7287\n",
      "Epoch 395/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0612 - acc: 0.9241 - val_loss: 0.1701 - val_acc: 0.7209\n",
      "Epoch 396/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0641 - acc: 0.9183 - val_loss: 0.1684 - val_acc: 0.7132\n",
      "Epoch 397/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0719 - acc: 0.8961 - val_loss: 0.1645 - val_acc: 0.7287\n",
      "Epoch 398/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0668 - acc: 0.9148 - val_loss: 0.1759 - val_acc: 0.7054\n",
      "Epoch 399/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0719 - acc: 0.9105 - val_loss: 0.1710 - val_acc: 0.7209\n",
      "Epoch 400/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0684 - acc: 0.9169 - val_loss: 0.1664 - val_acc: 0.7287\n",
      "Epoch 401/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0725 - acc: 0.9097 - val_loss: 0.1678 - val_acc: 0.7287\n",
      "Epoch 402/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0715 - acc: 0.9112 - val_loss: 0.1573 - val_acc: 0.7442\n",
      "Epoch 403/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0705 - acc: 0.9090 - val_loss: 0.1727 - val_acc: 0.7132\n",
      "Epoch 404/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0666 - acc: 0.9112 - val_loss: 0.1696 - val_acc: 0.7132\n",
      "Epoch 405/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0682 - acc: 0.9126 - val_loss: 0.1828 - val_acc: 0.6899\n",
      "Epoch 406/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0737 - acc: 0.9054 - val_loss: 0.1766 - val_acc: 0.7054\n",
      "Epoch 407/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0680 - acc: 0.9062 - val_loss: 0.1649 - val_acc: 0.7287\n",
      "Epoch 408/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0656 - acc: 0.9176 - val_loss: 0.1745 - val_acc: 0.7054\n",
      "Epoch 409/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0675 - acc: 0.9198 - val_loss: 0.1612 - val_acc: 0.7209\n",
      "Epoch 410/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0670 - acc: 0.9140 - val_loss: 0.1682 - val_acc: 0.7132\n",
      "Epoch 411/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0640 - acc: 0.9198 - val_loss: 0.1563 - val_acc: 0.7364\n",
      "Epoch 412/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0647 - acc: 0.9212 - val_loss: 0.1678 - val_acc: 0.7209\n",
      "Epoch 413/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0604 - acc: 0.9241 - val_loss: 0.1733 - val_acc: 0.7132\n",
      "Epoch 414/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0618 - acc: 0.9234 - val_loss: 0.1818 - val_acc: 0.6977\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0704 - acc: 0.9062 - val_loss: 0.1640 - val_acc: 0.7364\n",
      "Epoch 416/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0716 - acc: 0.9097 - val_loss: 0.1693 - val_acc: 0.7132\n",
      "Epoch 417/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0653 - acc: 0.9183 - val_loss: 0.1669 - val_acc: 0.7209\n",
      "Epoch 418/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0631 - acc: 0.9219 - val_loss: 0.1553 - val_acc: 0.7597\n",
      "Epoch 419/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0609 - acc: 0.9198 - val_loss: 0.1576 - val_acc: 0.7364\n",
      "Epoch 420/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0633 - acc: 0.9241 - val_loss: 0.1765 - val_acc: 0.6899\n",
      "Epoch 421/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0628 - acc: 0.9219 - val_loss: 0.1719 - val_acc: 0.7054\n",
      "Epoch 422/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0617 - acc: 0.9183 - val_loss: 0.1733 - val_acc: 0.7132\n",
      "Epoch 423/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0663 - acc: 0.9162 - val_loss: 0.1675 - val_acc: 0.7209\n",
      "Epoch 424/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0680 - acc: 0.9097 - val_loss: 0.1622 - val_acc: 0.7287\n",
      "Epoch 425/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0670 - acc: 0.9198 - val_loss: 0.1653 - val_acc: 0.7132\n",
      "Epoch 426/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0632 - acc: 0.9262 - val_loss: 0.1544 - val_acc: 0.7519\n",
      "Epoch 427/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0637 - acc: 0.9169 - val_loss: 0.1609 - val_acc: 0.7287\n",
      "Epoch 428/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0636 - acc: 0.9155 - val_loss: 0.1664 - val_acc: 0.7054\n",
      "Epoch 429/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0665 - acc: 0.9140 - val_loss: 0.1673 - val_acc: 0.7209\n",
      "Epoch 430/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0579 - acc: 0.9298 - val_loss: 0.1759 - val_acc: 0.7132\n",
      "Epoch 431/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0620 - acc: 0.9212 - val_loss: 0.1791 - val_acc: 0.6822\n",
      "Epoch 432/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0677 - acc: 0.9169 - val_loss: 0.1638 - val_acc: 0.7364\n",
      "Epoch 433/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0655 - acc: 0.9133 - val_loss: 0.1729 - val_acc: 0.7132\n",
      "Epoch 434/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0616 - acc: 0.9248 - val_loss: 0.1687 - val_acc: 0.7209\n",
      "Epoch 435/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0601 - acc: 0.9262 - val_loss: 0.1672 - val_acc: 0.7364\n",
      "Epoch 436/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0622 - acc: 0.9226 - val_loss: 0.1858 - val_acc: 0.6977\n",
      "Epoch 437/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0654 - acc: 0.9148 - val_loss: 0.1722 - val_acc: 0.7364\n",
      "Epoch 438/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0567 - acc: 0.9298 - val_loss: 0.1779 - val_acc: 0.7287\n",
      "Epoch 439/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0590 - acc: 0.9312 - val_loss: 0.1761 - val_acc: 0.7364\n",
      "Epoch 440/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0676 - acc: 0.9126 - val_loss: 0.1887 - val_acc: 0.6899\n",
      "Epoch 441/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0601 - acc: 0.9262 - val_loss: 0.1723 - val_acc: 0.7287\n",
      "Epoch 442/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0601 - acc: 0.9277 - val_loss: 0.1701 - val_acc: 0.7442\n",
      "Epoch 443/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0584 - acc: 0.9269 - val_loss: 0.1691 - val_acc: 0.7364\n",
      "Epoch 444/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0606 - acc: 0.9269 - val_loss: 0.1710 - val_acc: 0.7287\n",
      "Epoch 445/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0607 - acc: 0.9269 - val_loss: 0.1698 - val_acc: 0.7364\n",
      "Epoch 446/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0650 - acc: 0.9191 - val_loss: 0.1913 - val_acc: 0.7054\n",
      "Epoch 447/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0642 - acc: 0.9234 - val_loss: 0.1887 - val_acc: 0.6977\n",
      "Epoch 448/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0628 - acc: 0.9248 - val_loss: 0.1762 - val_acc: 0.7132\n",
      "Epoch 449/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0593 - acc: 0.9291 - val_loss: 0.1815 - val_acc: 0.6977\n",
      "Epoch 450/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0655 - acc: 0.9133 - val_loss: 0.1831 - val_acc: 0.6899\n",
      "Epoch 451/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0579 - acc: 0.9255 - val_loss: 0.1752 - val_acc: 0.6899\n",
      "Epoch 452/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0571 - acc: 0.9255 - val_loss: 0.1823 - val_acc: 0.7054\n",
      "Epoch 453/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0654 - acc: 0.9255 - val_loss: 0.1655 - val_acc: 0.7209\n",
      "Epoch 454/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0574 - acc: 0.9305 - val_loss: 0.1749 - val_acc: 0.7054\n",
      "Epoch 455/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0615 - acc: 0.9191 - val_loss: 0.1707 - val_acc: 0.7132\n",
      "Epoch 456/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0595 - acc: 0.9298 - val_loss: 0.1831 - val_acc: 0.6899\n",
      "Epoch 457/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0593 - acc: 0.9269 - val_loss: 0.1775 - val_acc: 0.6977\n",
      "Epoch 458/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0564 - acc: 0.9284 - val_loss: 0.1731 - val_acc: 0.7054\n",
      "Epoch 459/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0584 - acc: 0.9284 - val_loss: 0.1661 - val_acc: 0.7442\n",
      "Epoch 460/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0613 - acc: 0.9219 - val_loss: 0.1611 - val_acc: 0.7597\n",
      "Epoch 461/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0594 - acc: 0.9284 - val_loss: 0.1531 - val_acc: 0.7752\n",
      "Epoch 462/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0607 - acc: 0.9162 - val_loss: 0.1670 - val_acc: 0.7442\n",
      "Epoch 463/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0604 - acc: 0.9148 - val_loss: 0.1709 - val_acc: 0.7132\n",
      "Epoch 464/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0596 - acc: 0.9277 - val_loss: 0.1609 - val_acc: 0.7597\n",
      "Epoch 465/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0589 - acc: 0.9291 - val_loss: 0.1576 - val_acc: 0.7674\n",
      "Epoch 466/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0590 - acc: 0.9219 - val_loss: 0.1617 - val_acc: 0.7519\n",
      "Epoch 467/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0594 - acc: 0.9248 - val_loss: 0.1688 - val_acc: 0.7132\n",
      "Epoch 468/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0597 - acc: 0.9312 - val_loss: 0.1667 - val_acc: 0.7364\n",
      "Epoch 469/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0575 - acc: 0.9241 - val_loss: 0.1641 - val_acc: 0.7442\n",
      "Epoch 470/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0529 - acc: 0.9370 - val_loss: 0.1585 - val_acc: 0.7442\n",
      "Epoch 471/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0597 - acc: 0.9248 - val_loss: 0.1506 - val_acc: 0.7907\n",
      "Epoch 472/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0540 - acc: 0.9312 - val_loss: 0.1535 - val_acc: 0.7674\n",
      "Epoch 473/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0545 - acc: 0.9312 - val_loss: 0.1570 - val_acc: 0.7674\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0564 - acc: 0.9284 - val_loss: 0.1499 - val_acc: 0.7752\n",
      "Epoch 475/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0570 - acc: 0.9291 - val_loss: 0.1695 - val_acc: 0.7287\n",
      "Epoch 476/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0590 - acc: 0.9191 - val_loss: 0.1545 - val_acc: 0.7752\n",
      "Epoch 477/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0541 - acc: 0.9305 - val_loss: 0.1709 - val_acc: 0.7209\n",
      "Epoch 478/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0581 - acc: 0.9226 - val_loss: 0.1605 - val_acc: 0.7364\n",
      "Epoch 479/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0588 - acc: 0.9219 - val_loss: 0.1521 - val_acc: 0.7674\n",
      "Epoch 480/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0562 - acc: 0.9312 - val_loss: 0.1505 - val_acc: 0.7674\n",
      "Epoch 481/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0511 - acc: 0.9341 - val_loss: 0.1512 - val_acc: 0.7674\n",
      "Epoch 482/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0510 - acc: 0.9413 - val_loss: 0.1577 - val_acc: 0.7519\n",
      "Epoch 483/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0541 - acc: 0.9319 - val_loss: 0.1568 - val_acc: 0.7674\n",
      "Epoch 484/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0555 - acc: 0.9319 - val_loss: 0.1607 - val_acc: 0.7597\n",
      "Epoch 485/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0600 - acc: 0.9191 - val_loss: 0.1639 - val_acc: 0.7519\n",
      "Epoch 486/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0530 - acc: 0.9298 - val_loss: 0.1628 - val_acc: 0.7597\n",
      "Epoch 487/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0561 - acc: 0.9334 - val_loss: 0.1816 - val_acc: 0.7132\n",
      "Epoch 488/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0556 - acc: 0.9319 - val_loss: 0.1744 - val_acc: 0.7209\n",
      "Epoch 489/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0564 - acc: 0.9291 - val_loss: 0.1624 - val_acc: 0.7597\n",
      "Epoch 490/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0572 - acc: 0.9291 - val_loss: 0.1801 - val_acc: 0.7132\n",
      "Epoch 491/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0592 - acc: 0.9241 - val_loss: 0.1735 - val_acc: 0.7287\n",
      "Epoch 492/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0542 - acc: 0.9312 - val_loss: 0.1603 - val_acc: 0.7597\n",
      "Epoch 493/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0533 - acc: 0.9362 - val_loss: 0.1834 - val_acc: 0.7209\n",
      "Epoch 494/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0551 - acc: 0.9319 - val_loss: 0.1758 - val_acc: 0.7287\n",
      "Epoch 495/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0606 - acc: 0.9255 - val_loss: 0.1679 - val_acc: 0.7287\n",
      "Epoch 496/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0579 - acc: 0.9319 - val_loss: 0.1555 - val_acc: 0.7752\n",
      "Epoch 497/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0525 - acc: 0.9391 - val_loss: 0.1572 - val_acc: 0.7752\n",
      "Epoch 498/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0565 - acc: 0.9334 - val_loss: 0.1623 - val_acc: 0.7597\n",
      "Epoch 499/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0571 - acc: 0.9234 - val_loss: 0.1638 - val_acc: 0.7597\n",
      "Epoch 500/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0578 - acc: 0.9205 - val_loss: 0.1600 - val_acc: 0.7752\n",
      "Epoch 501/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0532 - acc: 0.9305 - val_loss: 0.1653 - val_acc: 0.7752\n",
      "Epoch 502/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0569 - acc: 0.9305 - val_loss: 0.1640 - val_acc: 0.7674\n",
      "Epoch 503/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0545 - acc: 0.9312 - val_loss: 0.1746 - val_acc: 0.7287\n",
      "Epoch 504/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0590 - acc: 0.9269 - val_loss: 0.1526 - val_acc: 0.7829\n",
      "Epoch 505/1000\n",
      "1396/1396 [==============================] - 4s 3ms/step - loss: 0.0486 - acc: 0.9391 - val_loss: 0.1543 - val_acc: 0.7829\n",
      "Epoch 506/1000\n",
      "1280/1396 [==========================>...] - ETA: 0s - loss: 0.0548 - acc: 0.9289"
     ]
    }
   ],
   "source": [
    "# Now, fit the model to the data\n",
    "history = model.fit([x, params], y, validation_data=([x_dev, params_dev], y_dev), epochs=1000, batch_size=128)\n",
    "\n",
    "# List all data in history\n",
    "print(history.history.keys())\n",
    "# Summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load pretrained conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('trained/conv_model_quickngood.json', 'r')\n",
    "conv_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(conv_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"trained/conv_model_quickngood.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Additional model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 2ms/step\n",
      "\n",
      "Performance on VALIDATION set\n",
      ".............................\n",
      "Loss: 0.1132218891266524\n",
      "Accuracy: 0.8372093023255814\n",
      "Precision: 0.9107142857142857\n",
      "Recall: 0.7611940298507462\n",
      ".............................\n",
      "List of indices of wrong guesses:\n",
      "[3, 10, 14, 17, 18, 35, 42, 43, 46, 47, 49, 53, 74, 83, 85, 88, 97, 104, 105, 113, 121]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model, get metrics back\n",
    "stats = model.evaluate([x_dev, params_dev], y_dev)\n",
    "# Calculate predictions vector from model\n",
    "predictions = model.predict([x_dev, params_dev])\n",
    "predictions = np.floor(predictions + 0.5)\n",
    "\n",
    "# Get vector mask for good and bad fits and right and wrong answers\n",
    "good_fits = y_dev\n",
    "bad_fits = 1 - good_fits\n",
    "wrong_answers = np.abs(np.subtract(predictions, good_fits))\n",
    "right_answers = np.subtract(1, wrong_answers)\n",
    "# Calculate true positives (tp), as well as (tn) (fp) (fn)\n",
    "true_positives = np.multiply(right_answers, good_fits)\n",
    "true_negatives = np.multiply(right_answers, bad_fits)\n",
    "false_positives = np.multiply(wrong_answers, good_fits)\n",
    "false_negatives = np.multiply(wrong_answers, bad_fits)\n",
    "# Calculate additional metrics\n",
    "precision = np.sum(true_positives) / np.sum(true_positives + false_positives)\n",
    "recall = np.sum(true_positives) / np.sum(true_positives + false_negatives)\n",
    "\n",
    "# Print stats\n",
    "print()\n",
    "print(\"Performance on VALIDATION set\")\n",
    "print(\".............................\")\n",
    "print(\"Loss: \" + str(stats[0]))\n",
    "print(\"Accuracy: \" + str(stats[1]))\n",
    "print(\"Precision: \" + str(precision))\n",
    "print(\"Recall: \" + str(recall))\n",
    "\n",
    "# Print list of indices of wrong answers\n",
    "bad_list = []\n",
    "for i in range(m_dev):\n",
    "    if wrong_answers[i] == 1:\n",
    "        bad_list.append(i)\n",
    "print(\".............................\")\n",
    "print(\"List of indices of wrong guesses:\")\n",
    "print(bad_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Look at an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: [1]\n",
      "prediction: [0.]\n",
      "(236, 348, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f56019245c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose an index \n",
    "index = 10\n",
    "\n",
    "# Print labels for this index\n",
    "print(\"label: \" + str(good_fits[index]))\n",
    "print(\"prediction: \" + str(predictions[index]))\n",
    "\n",
    "# Show image\n",
    "this_image = x[index]\n",
    "print(str(this_image.shape))\n",
    "plt.imshow(np.uint8(utils.get_printable_image(this_image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save convolutional model to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#plot_model(simple_model, to_file='simple_model.png')\n",
    "#SVG(model_to_dot(simple_model).create(prog='dot', format='svg'))\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"trained/conv_model_all_1000.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"trained/conv_model_all_1000.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
