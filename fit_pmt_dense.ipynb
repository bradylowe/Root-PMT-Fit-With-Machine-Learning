{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root fit analyzing neural network\n",
    "\n",
    "\n",
    "By Brady Lowe\n",
    "\n",
    "lowebra2@isu.edu\n",
    "\n",
    "7/25/2018\n",
    "\n",
    "\n",
    "This Jupyter notebook was written to both develope and explain how we can use\n",
    "neural networks to analyze the output of root fits to raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load some packages\n",
    "\n",
    "# Keras packages for network\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, Conv2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "# For saving model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Some items for plotting and drawing\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Need numpy\n",
    "import numpy as np\n",
    "import nn_utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load root fit data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(m_train, height, width, channels): (679, 236, 348, 3)\n",
      "m_test: 85\n"
     ]
    }
   ],
   "source": [
    "# Load dataset with m examples\n",
    "m = -1\n",
    "train_images, train_labels, test_images, test_labels = nn_utils.load_dataset(m)\n",
    "\n",
    "# Grab number of images\n",
    "m_train = train_images.shape[0]\n",
    "m_test = test_images.shape[0]\n",
    "\n",
    "# Grab dimensions of picture\n",
    "h = train_images.shape[1]\n",
    "w = train_images.shape[2]\n",
    "c = train_images.shape[3]\n",
    "\n",
    "# Print dimensions\n",
    "print(\"(m_train, height, width, channels): (\" + str(m_train) + \", \" + str(h) + \", \" + str(w) + \", \" + str(c) + \")\")\n",
    "print(\"m_test: \" + str(m_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: good\n",
      "label: [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d4d6e2a3c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD8CAYAAABTjp5OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3X18lOWd7/HPL5lolEEnlJSACSYs\ntKhpSSV1o0vFttqgbkUXt3VXXbqH1u1Zbevpbltsz9H2VFd7fDjYc1ptF7vafahucausWFGs4lIF\nRTdIKCBZBRMwgsi0jC6YCdf+cd0ThjBJJsk8Zr7v12tec8+de6755Z7JL9dc9/VgzjlERKTwleU7\nABERSY8StohIkVDCFhEpEkrYIiJFQglbRKRIKGGLiBSJrCVsM5tnZlvNrMPMFmfrdURESoVlox+2\nmZUDrwDnAV3AC8CfOOd+k/EXExEpEdmqYZ8BdDjnXnXOvQfcD8zP0muJiJSEUJbKPQnoTHrcBfz+\nQAdPnDjR1dfXZykUEZHC9uKLL77lnKse6rhsJWxLse+Ithczuwq4CmDq1KmsX78+S6GIiBQ2M9uR\nznHZahLpAuqSHtcCu5IPcM792DnX7Jxrrq4e8h+LiEjJy1bCfgGYYWYNZnYMcBmwPEuvJSJSErLS\nJOKci5vZNcBKoBz4iXNuUzZeS0SkVGSrDRvn3KPAo9kqX0Sk1Giko4hIkVDCFhEpEkrYIiJFQglb\nRKRIKGGLiBQJJWwRkSKhhC0iUiSUsEVEioQStohIkVDCFhEpEkrYIiJFQglbRKRIKGGLiBQJJWwR\nkSKhhC0iUiSUsEVEioQStohIkVDCFhEpEkrYIiJFQglbRKRIKGGLiBQJJWwRkSKhhC0iUiSUsAtI\nPA4rVsDtt0NXV76jEZFCo4RdAHp6eti5cydLljiWLvXJ+tOfVtIWkSMpYedZPB5n+fLlfPWr/5uV\nK3/HnDmwaBFUVkI0mu/oRKSQKGHn2YEDB3j22Wd55pkNvPbau7S2Qm2tv61cme/oRKSQhPIdQKkL\nh8Nce+217N59Jtu2TSQUihEOV9LYGCIWy3d0IlJIlLALQF1dHfX1k+npeYO77lrC2WefxXvvXcR7\n71UQj0NI75KIoIRdMEKhEE899QjvvPMjfvWrx2ltncS6dXPo7vbNIyIiasMuEO3t8OEPT6OhoYGP\nfvSjXHJJA6GQ7+onIgKqYReM7m74/vc/QSz2Q6ZNm8ahQ1OIx2HDBqivz3d0IlIIVMMuEKEQjK+q\noOFjH2PcSScxebLR0gJtbfmOTEQKhRJ2gYgDDwLnAz8ACEE4nNeQRKTAKGEXiC1x+P8hiADLgO58\nByQiBUcJu0C81QLNNXAzUAlE8TXs9naNeBQRTwm7QEQWwudCMAeYB9wHzF8Ab72lhC0i3qgStplt\nN7ONZtZmZuuDfRPM7Akz2xbcV2Um1LErGoVIGGYFj5uAtahZRESOlIka9sedc03Ouebg8WLgSefc\nDODJ4LEMIhqFcORwH8tZBNtBP+wNG/IXm4gUjmw0iczHf6MnuL84C68x5syLQE2/fTU1qGufiPQZ\nbcJ2wONm9qKZXRXsm+ScewMguH//KF+jJIQ5XMMO4bv5bVLXPhFJMtqRjn/gnNtlZu8HnjCzLek+\nMUjwVwFMnTp1lGGMLTVAC5CoWMdiaBIoERldDds5tyu43w38AjgDeNPMJgME97sHeO6PnXPNzrnm\n6urq0YRR9DZs9zXshBCHHzc1wdq1fui6iJS2ESdsMxtnZuMT28CngHZgObAwOGwh8PBogxzr2rZD\n6wA/mzULTQIlIsDomkQmAb8ws0Q5/+Sce8zMXgD+2cwWAa8Dfzz6MMe+VE3VMXxbtogIjCJhO+de\n5XDX4eT9e4FPjiYo8X2xb8N3uRERAY10LFiJvthxfHOIlgsTESXsQhAf+KtOJOL7Y2tBXhFRws6z\n7dvh3hD0XwUsAkwEnoxAY6Nq2CKihF2wIkAj/sIjHO6LLSKlSwm7AISGqD2rL7aIgBJ2/gVt1INR\nX2wRASXsvNuwHWLn5jsKESkGmp0iz9raIBrBN1on6enpIfrOO3R2dtIZjQB1+QhPRAqIEnYBisVi\nLFu2jJUvvcSOd97BxSYSi/0vUo+HFJFSoSaRAlRZWcmZZ57JmVVVjL/ySn5//oWEQpVayECkxKmG\nnW9xCPfrJRIKhfjABz7AV7/+dV459lguPlTGnn8vo60N5musukjJUsLOo97eXtwHy5h3wI76mZkx\nbtw4QsAxaCEDEVGTSN50dnZy55138lz5c4SbUx8Twi9moP+qIgJK2HkRi8VYsmQJ119/B0/+au+A\nx9XgF8TcmrPIRKSQKWHnQWVlJWeddRZTppxKb++HBjwuBHTjV4UQEVHCzoNQKMSCBQt4/PnHmXNa\nPQsGGZoeDW4LFsCqVX6yKBEpTWoezacIhC5Nr3d1OKxFeEVKnWrYIiJFQnW2fIoBa4A5DFjNPidp\nWyvPiJQ21bDzaMMWiNYDlQMfMwvYDn2z+mnlGZHSpYSdR23tEK1k0O85UeBeAK08I1LylLDz6bfQ\ntOGoifpERFJSG3Y+NUETgyfsMDAPzdMnIkrY+TV36EMOAG3BvYiUNjWJFLg4frRjYnUwLcYrUrqU\nsPMkGvWrzQwleQIoLcYrUtqUsPMkGoX2NRAeoracPAGUFuMVKW1K2PlSC7WXwoIhDgvhu2mrN5+I\nKGHnyzCuJrYFNxEpbUrY+VKJ79M3yCjH/hLNIVrbUaQ0KWHnyzCWk5nrHNN37mTbtn9j9uyetC5W\nisjYo4SdJ8Ppnjdt/35WbNrEl6//Js8//6vsBiYiBUsDZ/Jk5WPQ3QLUDn3sK7t388SUKbz79tuE\n33o167GJSGFSws6T2E5ofBEiaSTs6dOnM3nvXv7wK1/hzXXnawIokRKlhJ0vacwjkhAG/nTCBP58\n0SLWTirnttuyHJuIFCQl7HyZlf6hB4ANZvSUl/cNnhGR0qOLjvmyPbilof98IiJSmoZM2Gb2EzPb\nbWbtSfsmmNkTZrYtuK8K9puZfd/MOszsZTM7PZvBF6t4HGITgfr0jh9GD0ARGcPSqWHfi5+SOdli\n4Enn3AzgyeAxwPnAjOB2FXBXZsIcW7q74bG7SbuGXQPcwOExNgcPHqSnpycrsYlI4RoyYTvnngHe\n7rd7PnBfsH0ffn6ixP6fOm8tEDGzyZkKdqyIxyE2HX/VMQ0h/ORPvwY6O19m796tLF68mJi6i4iU\nlJG2YU9yzr0BENy/P9h/EtCZdFxXsE+ShSDSDU3DyLfbg1tLyylccMFUrr32WsJhrUMjUkoy3Sxq\nKfa5lAeaXYVvNmHq1KkZDqPA1UDkczBrGPOIRIP7iooKIpEIdXVaCVKk1Iy0hv1moqkjuN8d7O8C\n6pKOqwV2pSrAOfdj51yzc665urp6hGEUqRGs+xXhyD7bmhNbpPSMNGEvBxYG2wuBh5P2/1nQW6QF\n+G2i6USSjGCmvsuBVnzXvqYmrTojUorS6db3M+A54INm1mVmi4BbgPPMbBtwXvAY4FHgVaAD+Fvg\nL7MSdZGLHYD4RIbVIHUA+A6+P/asWaphi5SiIVOGc+5PBvjRJ1Mc64CrRxvUWLfyEYg1QWhm+s9J\nrpSrb4hIadJIxzyI7YVzf+37V6drBM3eIjLGaPBcPlzuJ3QazslXDVtEVMPOh+2kPcoxIbmGHQpp\nmTCRUqSEnQ/1pD2PSELyBFA1NWiZMJESpISdD9sZdg07AnwuuNf0qiKlSQk7x4Y7j0hCBD/a8b6h\nDhSRMUsJO8e6u2HVMgiPoB91PYdbUoaziK+IjA1K2DkWB8K/hta3hv/ctuAGsHatRjuKlBol7Fyr\ngdB3ITxxdMWEQqphi5QaJexcG8UImHOCm4iUJiXsXBvBxE8Js/CdS6L42nU0GtciBiIlRAk7x0Yy\n8VPfc4HHgvuaGvjmN1dzww030NnZOcQzRWQsUMLOsZWPQKxjZHMCJFfOGxvh8cef40c/+hFLlixR\nTVukBChh59hIJn5K6N/8XV09kVNOOYWzzjqLysoRtLGISFHRmLlcG8HETwn9m78vu+wyvvSlT1FX\nV0dIwx9FxjzVsHNtO8Melp6Q3IYNEApFmDp1GhUVFZmITEQKnBJ2rtUz7ImfUmlq0uAZkVKj79G5\nNorFzuuBbwM78MuEafCMSGlRDTuHotHRT4uaPDxdREqLEnYObd8e5cU73ubAynX09PSMqIz64Jao\nXWshA5HSoYSdI21tbfzwn37InnGv8MiNN7Ju3bqRlRPcamqgpUULGYiUErVh50h9fT1z5s1hedmJ\nfLT6ozQ0NIyqvFAIwuEMBSciRUE17ByJRCLMaZ7DjHdm8FdX/xVTpkzJSLmaF1ukdChh51DZ8WWE\nZocY975xmNmIyohwuKOJuvaJlBYl7FwaxdSqCZcDrcG2uvaJlBYl7FwKA/OC+xE6AHwnQ+GISHFR\nws6hDesh3jW6K72J+UREpPQoYedQ2zpoWTmymfoSEq0qoL7YIqVGCTuXLofwgtHVsONA4hqj+mKL\nlBYl7CJTj59PBI7si93Z2ckdd9zBo48+OuJRlCJS2DRwJkficYhlaLBLGzA32A6HYdWqGK+/voQH\nHvgRDQ0NnHDCCcyZM2f0LyQiBUU17Bzp7oa134Om6OjLqk/abm2FaLSSU089i1NPPZWWlpZRj6IU\nkcKkGnaOxMMQmu5XPh+tNmB+sB0OQ2VliIsuuohLLvkIkUiEqqqqDLyKiBQa1bBzJYwf8ZLh+T8S\nPUV+85sKpk2bxoQJE0Y8ilJECpsSdq5kYJRjKuopIlI61CSSK4lRjhmQvGiNZu0TKR2qYReh+UD/\na5eatU9k7BsyYZvZT8xst5m1J+37tpntNLO24HZB0s+uM7MOM9tqZq2pSy09mUyoIQ6vnA6atU+k\nVKRTw76X1F/m/69zrim4PQpgZqcClwGnBc/5oZmVZyrYYrbyEYh1ZKYNqjK4JWjWPpHSMGTCds49\nA7ydZnnzgfudcwedc68BHcAZo4hvzIjVwrmx0c0j0lcWR9awNaeISGkYTRv2NWb2ctBkkuj4exLQ\nmXRMV7BP5kC4OTM17BBHlqOeIiKlYaQJ+y7g9/Azfb4B3B7sT9UB2KUqwMyuMrP1ZrZ+z549Iwyj\nOMTjvg07U2qBB5MeJ3qK6MKjyNg2ooTtnHvTOdfrnDsE/C2Hmz26gLqkQ2uBXQOU8WPnXLNzrrm6\nunokYRSN7m5YtQzCGUym9f0e68KjyNg3ooRtZpOTHl4CJHqQLAcuM7NjzawBmAE8P7oQi1887GvA\nrRkcNNO/9UMXHkXGviGbVM3sZ8A5wEQz6wJuAM4xsyZ8c8d24C8AnHObzOyfgd/gp26+2jnXm53Q\ni0gEQpdmfFT6UZKbXnp7eykrK9MwdZExZMiE7Zz7kxS77xnk+JuAm0YTlAxfJOIvPq5cCSee2MnP\nf/5zZs6cyXnnnUdFRUW+wxORDNDQ9CI1E/8VJvEGRiLQ2AgdHTFuu20J99yjubFFxhoNTS9SD3F4\nqbCEpiZoa6tk2jTNjS0yFqmGnQMb2iBaz5GzNo1SE0eOdgR/4bGyMsQFF1zEpz+tubFFxhol7Bxo\na4P6KETOyWCZpJ6pNR6HgwcraGyclrkXE5GCoCaRXLjYN1dksIJNN74NO1nyhUcRGXtUw86FTGbq\nwV4muPCYyVGVIlI4VMMuUjWk/m8bDkN7O0QzsNiviBQWJewsi+KHgWZ60MxMUneGX7TI398zYE95\nESlWSthZFsW3N+dqJQc1i4iMXUrYORAi8zXsCAM3jatZRGRsUsIuUvOD+1Q5ubUVurr8TUTGDiXs\nLNvQlr2a7kOkTti1tf6m7n0iY4sSdpa1tUF9W8569gFHt2P39mrCRJGxQAk727IwaAaANWtg+3a4\n805YseKoibAT7dgbN3Zy55130tPTk+kIRCTHlLCzbbCrg6Nx002+rWX9erjmmqPaP1pb/cx93/72\nEq6//nrWrVuXhSBEJJeUsItRNEqkpoaL6+vh5pt9+8fSpUc0lkciUFlZyfHH+5n7NGufSPFTws6i\naAzaOmDjxo10dnYO/YR0rV5N5BvfgEiEh2tr4YtfhI4OWL2675CaGpg3L8T+/Rdx9933M2XKlMy9\nvojkhRJ2Fq3v6mBNvItf3nILS5YsIZaJ0SzRKPzDP8D06UQJeom0tsK8eXDvvX217FAIFiyAvXsr\nmDBhmpYKExkDlLCzqKa2hnHH9jA9FuOss86isrL/DNYjsHq172AdChHGD3uPhkIwZ46vZSd1vo4E\nbecbNoz+ZUUk/zRbXxb9RzhMFWF+8eDD1GfiTHd1wW23weLFACwAHsHXsiPz5/uEfeWV8K//CrW1\n1NbCX/+1f8r8+YMVLCLFQDXsLGoD4msg9FaGCnzxRX8/e3bqn7e2QmXlERcfBzpURIqPEnaWzZsD\nNRMzUFCi7frcc/0VxVQSQxwffLCvX3ZNDbS0+Ie9vb045zIQjIjkgxJ2loXD/gLgqEWj0N3tryQG\nBYboNy92JAJXXAGrVvlj8YfOmQNPPeUH0Pzyl7/UIBqRIqU27CyJxqCtG5qmZ6jAxJXDyOFRODXA\nxcBWoDaxc9asIICor23jm0Xmzn2EN9+8noaGBk444QTmzJmTocBEJFdUw86SaCVsr/Grm49aPO6H\nore0HNEcEgK2AGuSj02xsGNNDfzud6dQW9tIS0uLBtGIFCnVsLMlBJEwzMpEWd3dsHat7/IxVPtK\nYuan7m6f6EMhQiGorv4YX/jCz1i48ESqqqoyEZWI5Jhq2MUg0etj1tHpv68vdvLOpiZfI+/o6Ns1\ne3Y5zz7bQFnZBA2iESlSSthZsqHDt2OPWjzue33U1BzRfp3Qil+C7IiEPXeub79esaJv1ze+AVu2\nHDF6XUSKjBJ2lrTVQH1lBibq6+72vT6uuCJlwg6Tol2rf7MIPn9Pn+4r3v1mYhWRIqGEnS1haApl\nIGEP0hwCPlnHgaNGnzc1+XbvoHtfJAKf+xw89phWohEpVkrYWZKxRctXrhywOQR8174W/KjKIySG\nOCZGR+JbSqZPh6efhp4ep5VoRIqMEnaWrIpBuGPo4wYVj/sacmPjgAl7wBXZE0Mc2w6n8kQt+5ln\nDrF06dPceeedmZ32VUSySgk7S8JhWDDaQTMrVvhmjUWLBj2sCVgFHLFIeigECxf6NpD29r7dF14Y\n58tffpdvfvMj3H33Gzz//PPE1agtUhSUsLOkhgy0X7e1HTVYJpVE6/ZRK6inWD49FApx4YVhzjkn\nQkPDdzj77IsIZWTsvIhkmxJ2ljQyyoQdjfqacU3NkINlIvh/EEddS4xEfMJfu/ao3Z//POzadTyP\nP16hXiMiRUIJOwuiMPqrjomFCi68cMhDI/h/EClfsrW1r6dI/92XXgq33HLE+BoRKWBK2FkQBT60\nc5Q9MNra/DR709NvCI/hu/gdIXGxcvv2w7dolFDIN41Pnw7XX3+Ql1/eoVn8RArckAnbzOrM7Ckz\n22xmm8zsK8H+CWb2hJltC+6rgv1mZt83sw4ze9nMTs/2L1FoYsCLq+8ZeQ+MYTSHJDQBa/GjHo8w\ncaLvZXLllfDnf+7vv/AFWLGC2po4l14a4/HH3+XKKx9g+fJHdQFSpIClU8OOA3/lnDsF3+X3ajM7\nFVgMPOmcmwE8GTwGOB+YEdyuAu7KeNQFbiWw5DvfGfnCu11d/tbamvZTZnF4EE2feBwefth3vP7W\nt+Dv/g7uusv/E7jmGnjwQaZOeYUpU15l8+b5PPHEaxw4cGD48YpITgyZsJ1zbzjnXgq29wObgZOA\n+cB9wWH34admJtj/U+etBSJmNjnjkReoeBy6Y3DqlCkjW3g3MXdIoodHmo4a8ZgoZ8kSf4Vx0yao\nr/e17Vtv9R2ylyyhpWsTt91inHHGBLq7/4JoNGWvbhEpAMNqwzazeuAjwDpgknPuDfBJHXh/cNhJ\nQHJbQFewryR0H4BV3fDAAw9w0UUj6DI3xNwhA0mMeFxDUMteudIn62uvhauv9j1FEsPca2t9jXve\nPCquv57z332Fr3/1BDZsOI6lSx0HD2oEpEghSjthm1kYeBC41jn3u8EOTbHvqIUEzewqM1tvZuv3\n7NmTbhgFLxqGyukwbdo0Kioqhl/AUAvtDiAEzCFox+7qgqVLYd48v6RYZeXhZpa+JwRXHVtasOuu\n44LyVdx0Uy8PPvgOf/M3W4cft4hkXVoJ28wq8Mn6H51z/xLsfjPR1BHc7w72dwF1SU+vBXb1L9M5\n92PnXLNzrrm6unqk8ReclcCBkXaTS2eh3UHMAojFiH7ve36o5aJFhy9a9luct2/frbdCYyOhpXcz\n5dDP2b9/Gbfe+j6iGZkbVkQyKZ1eIgbcA2x2zt2R9KPlwMJgeyHwcNL+Pwt6i7QAv000nYx10Ris\n6YBzh59rvUQtOGmh3eGIxOPUxOOsnDXLN3kkt4FfcYUfpt6/03VtLXzxi9DezozVT/KpT7zK+963\njRUrKjWgRqTQOOcGveG/aTvgZfykcG3ABcD78L1DtgX3E4LjDfgB8B/ARqB5qNeYPXu2Gwtuc85d\n6pzbN5Inb97sXEuLcw89NLIXD56/8aGHXItzbmPKAG9zrrHRH9vfvn3OXXGFc/X1zt1/v2toWOum\nTDnorrvugOvsHFlIIpIeYL0bIk8654Ze09E5t4bU7dIAn0xxvAOuHs4/jbEgCqyJx/nA228zrqoK\nhtt+/cADvrY7d+7wX7yrC266CWbOpHbuXGrx7Vcz6be4wWc/61cweOABXwNPrsVHInDzzfC1r8GN\nNzJuXC27dp3ND3/4RV577VhuuMEPstG0IyL5o5GOGbIaeLqjg198/vMsX758+AU89pjvajeMniGA\nT9bXXee3v/tdIpEIVwCPAUc1pdfW+tdYtuzo9uzEz2+9FaZP53tfuoQbbzyOJUt62bfvP/mjP+rl\nppv8MmMHD/Ymvn2JSA4pYWdAVwz+rsfRu2IFu1av5tlnnx1mAV2+R8cwBsr0PS+RrG++ua/Nei7+\nSu9NpJjBb+5cvxrNjTce3Z4djfokfu65nL98Of/jd2/zuR0/4BL7Mu+9cjP33riFP74kzte//lse\neaSD9947NLx4RWRUrBBqSs3NzW79+vX5DmPYnHPs27+fm18t49Fpx3PNi6t596WX+MxnPkNdXd3Q\nBcDhpJuUcNOyZYtvBoGUz12BH3q6GPgs/ZpGkhP9N77h71euPGJJMSIRX+sHojU17O013t19Ao/3\nns+v7UzeqD2NC//bNOb9YZyTTw4xYUIZZWVlWpFdZATM7EXnXPOQxylhp885h5nR29vLoUOHePX1\n17l9xw7+pa6OK99+m785/XSOKSujvLx86MLicZ8kly71XfD+/u/TDyQahfPPh5kz4bvfTZno48D3\ngPvxSfvy/s9fu9bPKZIwc+bhWn447Burv/Y1n7Qvvpj//MQnOKazk/IXXmDvuq3s2n0Mv7Lz2Fp9\nJj2zPsz7T3+b5uYKZs+exeTJRlnZIcrLy3HOcejQofTOiUiJSjdhl/wlJOcc+/btIxqNUltbSywW\nIxqN9tWQOzs7iUQixGIx2tvbmdnYyEPPPcdbDQ08tGcPO+rqsFtuoWziRHpPO43y8CBDu6NRf9uw\nwV/8W7PGJ8khVpTpe14sdrgmfM01furVQZYOuxqoB24BwrEYsx57jMjOnUTWrPG17JYW/4/j6af9\n/fTpPllHIv52660+kS9bxnHr1/tYL76Y4//0eE596ik+9Nwqom1L6Xqjlp+uvIQ7Iq2cOGUH533q\nEMcc8x7HHXccx1T8hmOO3cy5n/wkvePr2P3e8YTDlfT0vHbUOQ6Hw3R1daXcjsViVFVVpXyvUm2P\nHz8+rbKrqqp47bXXhiwv+TOxf//+QWNNLnvfvn198adTdmdnJ7W1tWmXHY1GiUQifWUkBmslf677\nn+cJEyYA0NPTk/L89D/PXV1dacWd/F6lE3einIHOTzplV1VV9X2rS/W3PH78+CMGsA32OxfDt8OS\nT9hPOcf/6+zk9R07+INIhM5g+2PBh/rf2tuZevLJGNC+bx/TYzE2zJhB9cGDXLhlCxPvvZfxzz7L\np+fNI3z77YO/WFubvyUScHOzT5T33JPe8xJrPFZW+kQ6xETWEXxzSAT4n5dfDjNnUl9RQVM87mvS\niZr56tW+/O3bYd8+38bd1HR4CPtnP+uXK4vFfNzOwRlnwAc/2Dfc/VhCzGQzcbYdsSBwee9+Qj09\n/PsLL7Ap5Hjp0IcZP95RWdl+1Dmuq6vj1wNsd3Z2ctoJJ7ApxXuVavvkk09Oq+zTTjiBX7a3D1le\n8mdiR2fnoLEml70pODbdsv8tiCXdsl/fsYOpJ5/cV0ZV8A+81zk2DvBZbgoe73vnnZTnp/95/vUg\n5yfVe9g5yPlJ9R4OdH7SKftDkQjlQaJN/p2TPweJczLY7/ylSIRPKGEXvoMHDrCpvZ2dO3cyadIk\nOjo62LlzJw0NDQBs2bqV/fv38/GPf5zTGhupq6lh8g9+wB/t3s151dUc09joJ1RKRyIRDtdIn4d/\ngy8ETluzhg1NTbTNn3/0QfPn+1vKAkL+n8PMmUO+Ti3Qe+gQGzdu9H80c+b0/fHNbm7mN089xd6d\nT9DYOJfVq7ccdY4PHjw44HbHtm3UnnRSyvcq1XZ5WVlaZdeedBJbtmwZsrzkz8Sm9vZBY00ue1N7\nOwcPHEi77C1btzKppibtsnfu3Mn+/fv7ykgkp+TPdf/z3DTLLyrX1dk5ZNmTJk0a9Pykeg87tm1L\nK+5EOQOdn3TK/sCMGRx//PFH/c7Jn4PkhD3Q73xwxgwIyilkJZ+wz62oYElVFZu7u7l44kS27t3L\n5u5uPhO8yWeVl/PBSIRzTjyRg5WV/mvU5ZcTiUSoqKqCIvivDL5ppB4/lWI2OTP21dURHT+e2nCY\nWLA96cQTWZ10nh8qLz/qHJ8S7E+1vXnPHs457jjOT/Fepdr+UJpln3PccdSXlw9ZXvJn4uUhYk0u\n+/yqKj44jLLPCmJJt+zN3d2cEtx/JhLpmxOip6KCuUn7k89FYg2jzkgk5fnpf54fGuT8pHoPN+/Z\nk1bciXIGOj/plP2pigoqUvx667LoAAAFQ0lEQVTOyZ+D5Mv/A/3O545k3p880EVHOOLCWP+LZL29\nver9kCHJ57a3tzflOR5oO3HBd6D3qv924v1Kp+xELOmUnfg9hipvJHEn4k2cn3TKPnToEGVlZSkv\n7KbzWR6q7OT3Kt2/k6HOT6r3ajRlD/Q7J38Okg0UVz6pl4iISJFIN2Fr4IyISJFQwhYRKRJK2CIi\nRUIJW0SkSChhi4gUCSVsEZEioYQtIlIklLBFRIqEEraISJFQwhYRKRJK2CIiRUIJW0SkSChhi4gU\nCSVsEZEioYQtIlIklLBFRIqEEraISJFQwhYRKRIFsUSYme0B3gHeyncsIzARxZ1Liju3FHdunOyc\nqx7qoIJI2ABmtj6dNc0KjeLOLcWdW4q7sKhJRESkSChhi4gUiUJK2D/OdwAjpLhzS3HnluIuIAXT\nhi0iIoMrpBq2iIgMIu8J28zmmdlWM+sws8X5jmcwZrbdzDaaWZuZrQ/2TTCzJ8xsW3BfVQBx/sTM\ndptZe9K+lHGa9/3g/L9sZqcXWNzfNrOdwTlvM7MLkn52XRD3VjNrzU/UYGZ1ZvaUmW02s01m9pVg\nf0Gf80HiLuhzbmaVZva8mW0I4v5OsL/BzNYF5/sBMzsm2H9s8Lgj+Hl9PuLOCOdc3m5AOfAfwDTg\nGGADcGo+Yxoi3u3AxH77/g+wONheDHyvAOI8GzgdaB8qTuAC4JeAAS3AugKL+9vAX6c49tTg83Is\n0BB8jsrzFPdk4PRgezzwShBfQZ/zQeIu6HMenLdwsF0BrAvO4z8DlwX77wb+e7D9l8DdwfZlwAP5\nON+ZuOW7hn0G0OGce9U59x5wPzA/zzEN13zgvmD7PuDiPMYCgHPuGeDtfrsHinM+8FPnrQUiZjY5\nN5EeaYC4BzIfuN85d9A59xrQgf885Zxz7g3n3EvB9n5gM3ASBX7OB4l7IAVxzoPzFgseVgQ3B3wC\nWBbs73++E+/DMuCTZmY5Cjej8p2wTwI6kx53MfgHJt8c8LiZvWhmVwX7Jjnn3gD/BwC8P2/RDW6g\nOIvhPbgmaDr4SVKTU0HGHXzd/gi+1lc057xf3FDg59zMys2sDdgNPIGv7Uedc/EUsfXFHfz8t8D7\nchtxZuQ7Yaf6L1fI3Vb+wDl3OnA+cLWZnZ3vgDKg0N+Du4DfA5qAN4Dbg/0FF7eZhYEHgWudc78b\n7NAU+/IWe4q4C/6cO+d6nXNNQC2+ln9KqsOC+4KJe7TynbC7gLqkx7XArjzFMiTn3K7gfjfwC/wH\n5c3E19ngfnf+IhzUQHEW9HvgnHsz+OM8BPwth7+CF1TcZlaBT3r/6Jz7l2B3wZ/zVHEXyzkHcM5F\ngafxbdgRMwsFP0qOrS/u4Ocnkn7TW0HJd8J+AZgRXN09Bn9BYHmeY0rJzMaZ2fjENvApoB0f78Lg\nsIXAw/mJcEgDxbkc+LOg50IL8NvE1/hC0K9t9xL8OQcf92VBD4AGYAbwfK7jA9/rA7gH2OycuyPp\nRwV9zgeKu9DPuZlVm1kk2D4OOBff/v4UcGlwWP/znXgfLgV+5YIrkEUn31c98VfMX8G3QX0r3/EM\nEuc0/BXyDcCmRKz4trAngW3B/YQCiPVn+K+yPfjaxaKB4sR/XfxBcP43As0FFvffB3G9jP/Dm5x0\n/LeCuLcC5+cx7jn4r9gvA23B7YJCP+eDxF3Q5xz4MPDvQXztwPXB/mn4fyAdwM+BY4P9lcHjjuDn\n0/L1WRntTSMdRUSKRL6bREREJE1K2CIiRUIJW0SkSChhi4gUCSVsEZEioYQtIlIklLBFRIqEEraI\nSJH4L5ygXa1fSwIXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d4d6d88320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print an image\n",
    "index = 420\n",
    "this_image = train_images[index]\n",
    "if train_labels[index] == 1:\n",
    "    print(\"label: good\")\n",
    "else:\n",
    "    print(\"label: bad\")\n",
    "print(\"label: \" + str(train_labels[index]))\n",
    "plt.imshow(np.uint8(nn_utils.get_printable_image(this_image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Train Simple neural network (LRU)\n",
    "\n",
    "Here, we will use simple layers of relu neurons that are all fully connected (some number of these layers from 0 to 5), and then we will have a single neuron output layer acting as a logistic regression unit (LRU). \n",
    "For this fully connected network, we will flatten our data into a single dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Properly shape data for LRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_x: 246384\n",
      "shape train_images_flat: 679, 246384\n",
      "shape test_images_flat: 85, 246384\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data for the network we will use (logistic regression)\n",
    "train_images_flat = train_images.reshape(m_train, -1)\n",
    "test_images_flat = test_images.reshape(m_test, -1)\n",
    "\n",
    "# Grab input dimensionality\n",
    "n_x = train_images_flat.shape[1]\n",
    "# Print sizes\n",
    "print(\"n_x: \" + str(n_x))\n",
    "print(\"shape train_images_flat: \" + str(train_images_flat.shape[0]) + \", \" + str(train_images_flat.shape[1]))\n",
    "print(\"shape test_images_flat: \" + str(test_images_flat.shape[0]) + \", \" + str(test_images_flat.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define keras layers (model)\n",
    "Just one neuron fully connected to all pixels in the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 246384)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 246385    \n",
      "=================================================================\n",
      "Total params: 246,385\n",
      "Trainable params: 246,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define input layer (flat)\n",
    "X = Input(shape=(n_x,))\n",
    "# Define output activation (sigmoid neuron)\n",
    "a = Dense(units=1, activation='sigmoid')(X)\n",
    "# Make the model\n",
    "simple_model = Model(inputs=X, outputs=a)\n",
    "# Print summary\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define keras ADDITIONAL layers (deeper model)\n",
    "This is a slightly larger fully-connected model.\n",
    "This model has 40 neurons in the first layer (fully\n",
    "connected to input layer), 30 neurons in the second \n",
    "layer, 20 neurons in the third layer, and a single\n",
    "neuron in the output layer. We implement dropout between\n",
    "some of the layers to help reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 246384)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 40)                9855400   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 9,857,271\n",
      "Trainable params: 9,857,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define input layer (flat)\n",
    "X = Input(shape=(n_x,))\n",
    "# First layer\n",
    "a = Dense(units=40, activation='relu')(X)\n",
    "# Add dropout for regularization\n",
    "a = Dropout(rate=0.6)(a)\n",
    "# Second layer\n",
    "a = Dense(units=30, activation='relu')(a)\n",
    "# Add dropout for regularization\n",
    "a = Dropout(rate=0.5)(a)\n",
    "# Third layer\n",
    "a = Dense(units=20, activation='relu')(a)\n",
    "# Define output activation (sigmoid neuron)\n",
    "a = Dense(units=1, activation='sigmoid')(a)\n",
    "# Make the model\n",
    "simple_model = Model(inputs=X, outputs=a)\n",
    "# Print summary\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define optimizer, loss, and metrics. Compile model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001)\n",
    "# Define loss\n",
    "loss = 'binary_crossentropy'\n",
    "# Define metrics to use\n",
    "metrics=[]\n",
    "metrics.append('accuracy')\n",
    "# Compile model\n",
    "simple_model.compile(loss=loss, optimizer='adam', metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit the model to the data (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1772 - acc: 0.9352\n",
      "Epoch 2/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1837 - acc: 0.9337\n",
      "Epoch 3/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2074 - acc: 0.9161\n",
      "Epoch 4/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2339 - acc: 0.9013\n",
      "Epoch 5/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2126 - acc: 0.9087\n",
      "Epoch 6/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1946 - acc: 0.9264\n",
      "Epoch 7/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2014 - acc: 0.9205\n",
      "Epoch 8/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1905 - acc: 0.9264\n",
      "Epoch 9/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2131 - acc: 0.9131\n",
      "Epoch 10/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1939 - acc: 0.9219\n",
      "Epoch 11/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2392 - acc: 0.8954\n",
      "Epoch 12/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1989 - acc: 0.9205\n",
      "Epoch 13/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1916 - acc: 0.9367\n",
      "Epoch 14/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1648 - acc: 0.9470\n",
      "Epoch 15/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2050 - acc: 0.9190\n",
      "Epoch 16/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2199 - acc: 0.9102\n",
      "Epoch 17/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2058 - acc: 0.9219\n",
      "Epoch 18/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1911 - acc: 0.9308\n",
      "Epoch 19/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2513 - acc: 0.9057\n",
      "Epoch 20/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2153 - acc: 0.9116\n",
      "Epoch 21/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2099 - acc: 0.9219\n",
      "Epoch 22/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2098 - acc: 0.9175\n",
      "Epoch 23/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2055 - acc: 0.9175\n",
      "Epoch 24/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1760 - acc: 0.9352\n",
      "Epoch 25/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1857 - acc: 0.9293\n",
      "Epoch 26/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1747 - acc: 0.9337\n",
      "Epoch 27/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1930 - acc: 0.9249\n",
      "Epoch 28/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2053 - acc: 0.9175\n",
      "Epoch 29/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1587 - acc: 0.9411\n",
      "Epoch 30/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1659 - acc: 0.9440\n",
      "Epoch 31/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1678 - acc: 0.9426\n",
      "Epoch 32/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1906 - acc: 0.9367\n",
      "Epoch 33/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1829 - acc: 0.9323\n",
      "Epoch 34/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1584 - acc: 0.9455\n",
      "Epoch 35/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2089 - acc: 0.9278\n",
      "Epoch 36/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1908 - acc: 0.9381\n",
      "Epoch 37/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2056 - acc: 0.9249\n",
      "Epoch 38/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2063 - acc: 0.9146\n",
      "Epoch 39/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1640 - acc: 0.9426\n",
      "Epoch 40/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1884 - acc: 0.9352\n",
      "Epoch 41/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1702 - acc: 0.9470\n",
      "Epoch 42/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1816 - acc: 0.9337\n",
      "Epoch 43/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1861 - acc: 0.9337\n",
      "Epoch 44/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1698 - acc: 0.9367\n",
      "Epoch 45/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1781 - acc: 0.9352\n",
      "Epoch 46/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2178 - acc: 0.9175\n",
      "Epoch 47/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1619 - acc: 0.9440\n",
      "Epoch 48/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1637 - acc: 0.9455\n",
      "Epoch 49/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1588 - acc: 0.9440\n",
      "Epoch 50/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1828 - acc: 0.9323\n",
      "Epoch 51/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1593 - acc: 0.9411\n",
      "Epoch 52/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1783 - acc: 0.9367\n",
      "Epoch 53/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1649 - acc: 0.9396\n",
      "Epoch 54/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1751 - acc: 0.9367\n",
      "Epoch 55/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1879 - acc: 0.9337\n",
      "Epoch 56/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1660 - acc: 0.9411\n",
      "Epoch 57/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1848 - acc: 0.9293\n",
      "Epoch 58/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1411 - acc: 0.9543\n",
      "Epoch 59/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1684 - acc: 0.9381\n",
      "Epoch 60/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1692 - acc: 0.9411\n",
      "Epoch 61/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1643 - acc: 0.9426\n",
      "Epoch 62/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1703 - acc: 0.9426\n",
      "Epoch 63/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1813 - acc: 0.9396\n",
      "Epoch 64/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1666 - acc: 0.9426\n",
      "Epoch 65/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1996 - acc: 0.9234\n",
      "Epoch 66/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2012 - acc: 0.9264\n",
      "Epoch 67/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1646 - acc: 0.9426\n",
      "Epoch 68/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2279 - acc: 0.9102\n",
      "Epoch 69/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2133 - acc: 0.9116\n",
      "Epoch 70/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1853 - acc: 0.9264\n",
      "Epoch 71/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1960 - acc: 0.9219\n",
      "Epoch 72/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1592 - acc: 0.9440\n",
      "Epoch 73/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1842 - acc: 0.9323\n",
      "Epoch 74/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1777 - acc: 0.9367\n",
      "Epoch 75/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1811 - acc: 0.9293\n",
      "Epoch 76/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1699 - acc: 0.9352\n",
      "Epoch 77/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1759 - acc: 0.9323\n",
      "Epoch 78/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1737 - acc: 0.9367\n",
      "Epoch 79/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1712 - acc: 0.9396\n",
      "Epoch 80/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2027 - acc: 0.9337\n",
      "Epoch 81/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1816 - acc: 0.9352\n",
      "Epoch 82/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1948 - acc: 0.9264\n",
      "Epoch 83/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1736 - acc: 0.9396\n",
      "Epoch 84/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1993 - acc: 0.9249\n",
      "Epoch 85/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1816 - acc: 0.9308\n",
      "Epoch 86/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1724 - acc: 0.9352\n",
      "Epoch 87/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1853 - acc: 0.9337\n",
      "Epoch 88/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.2058 - acc: 0.9146\n",
      "Epoch 89/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1864 - acc: 0.9352\n",
      "Epoch 90/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1528 - acc: 0.9470\n",
      "Epoch 91/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1544 - acc: 0.9470\n",
      "Epoch 92/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1658 - acc: 0.9381\n",
      "Epoch 93/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1743 - acc: 0.9323\n",
      "Epoch 94/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1648 - acc: 0.9426\n",
      "Epoch 95/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1758 - acc: 0.9323\n",
      "Epoch 96/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1393 - acc: 0.9529\n",
      "Epoch 97/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1700 - acc: 0.9396\n",
      "Epoch 98/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1626 - acc: 0.9485\n",
      "Epoch 99/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1640 - acc: 0.9543\n",
      "Epoch 100/100\n",
      "679/679 [==============================] - 2s 2ms/step - loss: 0.1866 - acc: 0.9426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc576a5518>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, fit the model to the data\n",
    "simple_model.fit(train_images_flat, train_labels, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load pretrained weights from disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('simple_model.json', 'r')\n",
    "simple_model_json = json_file.read()\n",
    "json_file.close()\n",
    "simple_model = model_from_json(simple_model_json)\n",
    "# load weights into new model\n",
    "simple_model.load_weights(\"simple_model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate the model on the dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 2ms/step\n",
      "\n",
      "Performance on DEV set\n",
      "..........................\n",
      "Loss: 1.22582657197\n",
      "Accuracy: 0.752941180678\n",
      "Precision: 0.717948717949\n",
      "Recall: 0.736842105263\n",
      "..........................\n",
      "List of indices of wrong guesses:\n",
      "[7, 9, 14, 17, 27, 28, 30, 31, 34, 36, 40, 48, 53, 55, 60, 71, 72, 76, 77, 82, 84]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model, get metrics back\n",
    "stats = simple_model.evaluate(x=test_images_flat, y=test_labels)\n",
    "# Calculate predictions vector from model\n",
    "predictions = simple_model.predict(x=test_images_flat)\n",
    "predictions = np.floor(predictions + 0.5)\n",
    "\n",
    "# Get vector mask for good and bad fits and right and wrong answers\n",
    "good_fits = test_labels\n",
    "bad_fits = 1 - good_fits\n",
    "wrong_answers = np.abs(np.subtract(predictions, test_labels))\n",
    "right_answers = np.subtract(1, wrong_answers)\n",
    "# Calculate true positives (tp), as well as (tn) (fp) (fn)\n",
    "true_positives = np.multiply(right_answers, good_fits)\n",
    "true_negatives = np.multiply(right_answers, bad_fits)\n",
    "false_positives = np.multiply(wrong_answers, good_fits)\n",
    "false_negatives = np.multiply(wrong_answers, bad_fits)\n",
    "# Calculate additional metrics\n",
    "precision = np.sum(true_positives) / np.sum(true_positives + false_positives)\n",
    "recall = np.sum(true_positives) / np.sum(true_positives + false_negatives)\n",
    "\n",
    "# Print stats\n",
    "print()\n",
    "print(\"Performance on DEV set\")\n",
    "print(\"..........................\")\n",
    "print(\"Loss: \" + str(stats[0]))\n",
    "print(\"Accuracy: \" + str(stats[1]))\n",
    "print(\"Precision: \" + str(precision))\n",
    "print(\"Recall: \" + str(recall))\n",
    "\n",
    "# Print list of indices of wrong answers\n",
    "bad_list = []\n",
    "for i in range(m_test):\n",
    "    if wrong_answers[i] == 1:\n",
    "        bad_list.append(i)\n",
    "print(\"..........................\")\n",
    "print(\"List of indices of wrong guesses:\")\n",
    "print(bad_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Look at an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: [1]\n",
      "prediction: [ 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1db0182ba20>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD8CAYAAABTjp5OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMLQTgd0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1db01581748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose an index \n",
    "index = 7\n",
    "# Print labels for this index\n",
    "print(\"label: \" + str(good_fits[index]))\n",
    "print(\"prediction: \" + str(predictions[index]))\n",
    "\n",
    "# Show image\n",
    "this_image = test_images[index]\n",
    "plt.imshow(np.uint8(nn_utils.get_printable_image(this_image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = simple_model.to_json()\n",
    "with open(\"simple_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "simple_model.save_weights(\"simple_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
