{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root fit analyzing neural network\n",
    "\n",
    "\n",
    "By Brady Lowe\n",
    "\n",
    "lowebra2@isu.edu\n",
    "\n",
    "7/25/2018\n",
    "\n",
    "\n",
    "This Jupyter notebook was written to both develope and explain how we can use\n",
    "neural networks to analyze the output of root fits to raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load some packages\n",
    "\n",
    "# Keras packages for network\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, Conv2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "# For saving model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Some items for plotting and drawing\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Need numpy\n",
    "import numpy as np\n",
    "import nn_utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load root fit data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(m_train, height, width, channels): (679, 236, 348, 3)\n",
      "m_test: 85\n"
     ]
    }
   ],
   "source": [
    "# Load dataset with m examples\n",
    "m = -1\n",
    "train_images, train_labels, test_images, test_labels = nn_utils.load_dataset(m)\n",
    "\n",
    "# Grab number of images\n",
    "m_train = train_images.shape[0]\n",
    "m_test = test_images.shape[0]\n",
    "\n",
    "# Grab dimensions of picture\n",
    "h = train_images.shape[1]\n",
    "w = train_images.shape[2]\n",
    "c = train_images.shape[3]\n",
    "\n",
    "# Print dimensions\n",
    "print(\"(m_train, height, width, channels): (\" + str(m_train) + \", \" + str(h) + \", \" + str(w) + \", \" + str(c) + \")\")\n",
    "print(\"m_test: \" + str(m_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: good\n",
      "label: [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d4d6e2a3c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD8CAYAAABTjp5OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJH4L5ygXa1fSwIXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d4d6d88320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print an image\n",
    "index = 420\n",
    "this_image = train_images[index]\n",
    "if train_labels[index] == 1:\n",
    "    print(\"label: good\")\n",
    "else:\n",
    "    print(\"label: bad\")\n",
    "print(\"label: \" + str(train_labels[index]))\n",
    "plt.imshow(np.uint8(nn_utils.get_printable_image(this_image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Train 3 layer ConvNet with 2 fully connected layers plus output layer\n",
    "\n",
    "For the convolutional layer, we will scan over our images with a certain stride and a certain kernal size. \n",
    "Each individual scan represents a single neuron in the next layer. Since each scan connects to kernal size squared\n",
    "neurons below it, convolutions reduce the number of degrees of freedom. Hopefully, through learning the right filters,\n",
    "we can preserve the important information as we reduce it in size.\n",
    "\n",
    "Once the image has gone through the convolutional layers (and therefore has been reduced to its features vector), we\n",
    "can send the resulting vector into some old-fashioned fully-connected layers, and finally into a logistic regression unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshape data for entry into keras convNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully reshaped data\n"
     ]
    }
   ],
   "source": [
    "train_images_conv = train_images.reshape(m_train, w, h, c)\n",
    "test_images_conv = test_images.reshape(m_test, w, h, c)\n",
    "input_shape = w, h, c\n",
    "print(\"successfully reshaped data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize\n",
    "filters = []\n",
    "kernels = []\n",
    "strides = []\n",
    "pools = []\n",
    "\n",
    "# Conv1\n",
    "filters.append(32)\n",
    "kernels.append(5)\n",
    "strides.append(2)\n",
    "pools.append(2)\n",
    "\n",
    "# Conv2\n",
    "filters.append(160)\n",
    "kernels.append(5)\n",
    "strides.append(2)\n",
    "pools.append(2)\n",
    "\n",
    "# Conv3\n",
    "filters.append(500)\n",
    "kernels.append(5)\n",
    "strides.append(1)\n",
    "pools.append(2)\n",
    "\n",
    "# Define dense (fully-connected) layer sizes\n",
    "fc1 = 30\n",
    "fc2 = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define keras layers (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 348, 236, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 172, 116, 32)      2432      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 172, 116, 32)      128       \n",
      "_________________________________________________________________\n",
      "a0 (Activation)              (None, 172, 116, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)     (None, 86, 58, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 41, 27, 160)       128160    \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 41, 27, 160)       640       \n",
      "_________________________________________________________________\n",
      "a1 (Activation)              (None, 41, 27, 160)       0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 20, 13, 160)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 16, 9, 500)        2000500   \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 16, 9, 500)        2000      \n",
      "_________________________________________________________________\n",
      "a2 (Activation)              (None, 16, 9, 500)        0         \n",
      "_________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)     (None, 8, 4, 500)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "fc0 (Dense)                  (None, 30)                480030    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "sigmoid (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,614,211\n",
      "Trainable params: 2,612,827\n",
      "Non-trainable params: 1,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define input layer (RGB image matrix)\n",
    "X = Input(shape=input_shape, name='Input')\n",
    "\n",
    "# Initialize activation as input\n",
    "a = X\n",
    "# Loop through all convolutional layers\n",
    "for i in range(len(filters)):\n",
    "    # Perform convolution\n",
    "    a = Conv2D(filters=filters[i], kernel_size=(kernels[i], kernels[i]), strides=(strides[i], strides[i]), name=('conv' + str(i)))(a)\n",
    "    # Normalize\n",
    "    a = BatchNormalization(axis=3, name=('bn' + str(i)))(a)\n",
    "    # Activate\n",
    "    a = Activation('relu', name=('a' + str(i)))(a)\n",
    "    # Max-pool\n",
    "    a = MaxPooling2D((2, 2), name=('max_pool' + str(i)))(a)\n",
    "\n",
    "# Flatten output of convNet\n",
    "a = Flatten()(a)\n",
    "# Define first fully connected layer\n",
    "a = Dense(units=fc1, activation='relu', name='fc0')(a)\n",
    "# Use some dropout here for regularization\n",
    "a = Dropout(rate=0.5)(a)\n",
    "# Define second fully connected layer\n",
    "a = Dense(units=fc2, activation='relu', name='fc1')(a)\n",
    "# Define output layer \n",
    "a = Dense(units=1, activation='sigmoid', name='sigmoid')(a)\n",
    "\n",
    "# Make the model\n",
    "conv_model = Model(inputs=X, outputs=a)\n",
    "\n",
    "# Print summary\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define optimizer, loss, and metrics. Compile model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "#opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001)\n",
    "opt = SGD(lr=1.0, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Define loss\n",
    "loss = 'mean_squared_error'\n",
    "# Define metrics to use\n",
    "metrics=[]\n",
    "metrics.append('accuracy')\n",
    "# Compile model\n",
    "conv_model.compile(loss=loss, optimizer='sgd', metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit the model to the data (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0058 - acc: 0.9926\n",
      "Epoch 2/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0074 - acc: 0.9897\n",
      "Epoch 3/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9912\n",
      "Epoch 4/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9926\n",
      "Epoch 5/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0078 - acc: 0.9882\n",
      "Epoch 6/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9941\n",
      "Epoch 7/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9912\n",
      "Epoch 8/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0071 - acc: 0.9897\n",
      "Epoch 9/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9926\n",
      "Epoch 10/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9867\n",
      "Epoch 11/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0082 - acc: 0.9867\n",
      "Epoch 12/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9912\n",
      "Epoch 13/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9926\n",
      "Epoch 14/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9912\n",
      "Epoch 15/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0066 - acc: 0.9882\n",
      "Epoch 16/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0070 - acc: 0.9897\n",
      "Epoch 17/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0083 - acc: 0.9882\n",
      "Epoch 18/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0089 - acc: 0.9838\n",
      "Epoch 19/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0027 - acc: 0.9985\n",
      "Epoch 20/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0074 - acc: 0.9882\n",
      "Epoch 21/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9956\n",
      "Epoch 22/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0069 - acc: 0.9882\n",
      "Epoch 23/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0091 - acc: 0.9853\n",
      "Epoch 24/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9941\n",
      "Epoch 25/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9912\n",
      "Epoch 26/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0064 - acc: 0.9912\n",
      "Epoch 27/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9897\n",
      "Epoch 28/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9897\n",
      "Epoch 29/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0066 - acc: 0.9882\n",
      "Epoch 30/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9941\n",
      "Epoch 31/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0063 - acc: 0.9941\n",
      "Epoch 32/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0068 - acc: 0.9897\n",
      "Epoch 33/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9926\n",
      "Epoch 34/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9941\n",
      "Epoch 35/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0108 - acc: 0.9809\n",
      "Epoch 36/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0099 - acc: 0.9823\n",
      "Epoch 37/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9956\n",
      "Epoch 38/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9926\n",
      "Epoch 39/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0069 - acc: 0.9882\n",
      "Epoch 40/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9956\n",
      "Epoch 41/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0070 - acc: 0.9897\n",
      "Epoch 42/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9971\n",
      "Epoch 43/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9926\n",
      "Epoch 44/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0074 - acc: 0.9838\n",
      "Epoch 45/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0078 - acc: 0.9882\n",
      "Epoch 46/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0077 - acc: 0.9897\n",
      "Epoch 47/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9941\n",
      "Epoch 48/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0095 - acc: 0.9794\n",
      "Epoch 49/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0058 - acc: 0.9926\n",
      "Epoch 50/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0062 - acc: 0.9897\n",
      "Epoch 51/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0065 - acc: 0.9912\n",
      "Epoch 52/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0070 - acc: 0.9926\n",
      "Epoch 53/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9941\n",
      "Epoch 54/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9941\n",
      "Epoch 55/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0068 - acc: 0.9926\n",
      "Epoch 56/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9912\n",
      "Epoch 57/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0065 - acc: 0.9912\n",
      "Epoch 58/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9912\n",
      "Epoch 59/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9985\n",
      "Epoch 60/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9897\n",
      "Epoch 61/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9941\n",
      "Epoch 62/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9912\n",
      "Epoch 63/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9912\n",
      "Epoch 64/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9956\n",
      "Epoch 65/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0058 - acc: 0.9882\n",
      "Epoch 66/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9897\n",
      "Epoch 67/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0082 - acc: 0.9897\n",
      "Epoch 68/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0060 - acc: 0.9926\n",
      "Epoch 69/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9912\n",
      "Epoch 70/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9941\n",
      "Epoch 71/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0089 - acc: 0.9823\n",
      "Epoch 72/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0080 - acc: 0.9867\n",
      "Epoch 73/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0071 - acc: 0.9867\n",
      "Epoch 74/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9956\n",
      "Epoch 75/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9926\n",
      "Epoch 76/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9926\n",
      "Epoch 77/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9926\n",
      "Epoch 78/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9926\n",
      "Epoch 79/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9882\n",
      "Epoch 80/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0059 - acc: 0.9882\n",
      "Epoch 81/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0074 - acc: 0.9853\n",
      "Epoch 82/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0067 - acc: 0.9897\n",
      "Epoch 83/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0068 - acc: 0.9926\n",
      "Epoch 84/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9897\n",
      "Epoch 85/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9956\n",
      "Epoch 86/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9941\n",
      "Epoch 87/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9926\n",
      "Epoch 88/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9971\n",
      "Epoch 89/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9926\n",
      "Epoch 90/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0075 - acc: 0.9853\n",
      "Epoch 91/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0068 - acc: 0.9926\n",
      "Epoch 92/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0066 - acc: 0.9897\n",
      "Epoch 93/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0063 - acc: 0.9882\n",
      "Epoch 94/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0066 - acc: 0.9882\n",
      "Epoch 95/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9912\n",
      "Epoch 96/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9912\n",
      "Epoch 97/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9912\n",
      "Epoch 98/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9941\n",
      "Epoch 99/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9912\n",
      "Epoch 100/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0065 - acc: 0.9853\n",
      "Epoch 101/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9985\n",
      "Epoch 102/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9882\n",
      "Epoch 103/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9926\n",
      "Epoch 104/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9912\n",
      "Epoch 105/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0071 - acc: 0.9853\n",
      "Epoch 106/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9941\n",
      "Epoch 107/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0066 - acc: 0.9882\n",
      "Epoch 108/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9941\n",
      "Epoch 109/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0059 - acc: 0.9897\n",
      "Epoch 110/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0062 - acc: 0.9912\n",
      "Epoch 111/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9971\n",
      "Epoch 112/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0073 - acc: 0.9853\n",
      "Epoch 113/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 114/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0074 - acc: 0.9912\n",
      "Epoch 115/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9926\n",
      "Epoch 116/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9882\n",
      "Epoch 117/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0069 - acc: 0.9853\n",
      "Epoch 118/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9926\n",
      "Epoch 119/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9941\n",
      "Epoch 120/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0060 - acc: 0.9897\n",
      "Epoch 121/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9912\n",
      "Epoch 122/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0063 - acc: 0.9853\n",
      "Epoch 123/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0085 - acc: 0.9867\n",
      "Epoch 124/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0067 - acc: 0.9897\n",
      "Epoch 125/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0060 - acc: 0.9912\n",
      "Epoch 126/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9926\n",
      "Epoch 127/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0066 - acc: 0.9867\n",
      "Epoch 128/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9926\n",
      "Epoch 129/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0064 - acc: 0.9897\n",
      "Epoch 130/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0063 - acc: 0.9897\n",
      "Epoch 131/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0077 - acc: 0.9853\n",
      "Epoch 132/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0062 - acc: 0.9882\n",
      "Epoch 133/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9926\n",
      "Epoch 134/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0060 - acc: 0.9853\n",
      "Epoch 135/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9926\n",
      "Epoch 136/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0066 - acc: 0.9867\n",
      "Epoch 137/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9897\n",
      "Epoch 138/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9956\n",
      "Epoch 139/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0029 - acc: 0.9941\n",
      "Epoch 140/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9912\n",
      "Epoch 141/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0062 - acc: 0.9912\n",
      "Epoch 142/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9941\n",
      "Epoch 143/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9941\n",
      "Epoch 144/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9941\n",
      "Epoch 145/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0068 - acc: 0.9912\n",
      "Epoch 146/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0026 - acc: 0.9941\n",
      "Epoch 147/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0068 - acc: 0.9897\n",
      "Epoch 148/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0074 - acc: 0.9823\n",
      "Epoch 149/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9941\n",
      "Epoch 150/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0078 - acc: 0.9867\n",
      "Epoch 151/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9926\n",
      "Epoch 152/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9912\n",
      "Epoch 153/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0064 - acc: 0.9897\n",
      "Epoch 154/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0069 - acc: 0.9897\n",
      "Epoch 155/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0074 - acc: 0.9867\n",
      "Epoch 156/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0074 - acc: 0.9882\n",
      "Epoch 157/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9941\n",
      "Epoch 158/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9941\n",
      "Epoch 159/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9926\n",
      "Epoch 160/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9956\n",
      "Epoch 161/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0066 - acc: 0.9882\n",
      "Epoch 162/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9867\n",
      "Epoch 163/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9941\n",
      "Epoch 164/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0069 - acc: 0.9853\n",
      "Epoch 165/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9956\n",
      "Epoch 166/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0059 - acc: 0.9912\n",
      "Epoch 167/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0027 - acc: 0.9985\n",
      "Epoch 168/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9912\n",
      "Epoch 169/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9926\n",
      "Epoch 170/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9941\n",
      "Epoch 171/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9926\n",
      "Epoch 172/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9912\n",
      "Epoch 173/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9926\n",
      "Epoch 174/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9941\n",
      "Epoch 175/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0059 - acc: 0.9897\n",
      "Epoch 176/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9956\n",
      "Epoch 177/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9926\n",
      "Epoch 178/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0059 - acc: 0.9853\n",
      "Epoch 179/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9912\n",
      "Epoch 180/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9941\n",
      "Epoch 181/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9912\n",
      "Epoch 182/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9926\n",
      "Epoch 183/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9912\n",
      "Epoch 184/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 185/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9897\n",
      "Epoch 186/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9926\n",
      "Epoch 187/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9882\n",
      "Epoch 188/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9897\n",
      "Epoch 189/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0033 - acc: 0.9941\n",
      "Epoch 190/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9926\n",
      "Epoch 191/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0060 - acc: 0.9912\n",
      "Epoch 192/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9926\n",
      "Epoch 193/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9926\n",
      "Epoch 194/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0059 - acc: 0.9912\n",
      "Epoch 195/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0060 - acc: 0.9897\n",
      "Epoch 196/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9956\n",
      "Epoch 197/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0062 - acc: 0.9882\n",
      "Epoch 198/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0030 - acc: 0.9956\n",
      "Epoch 199/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9926\n",
      "Epoch 200/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0029 - acc: 0.9971\n",
      "Epoch 201/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9926\n",
      "Epoch 202/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9926\n",
      "Epoch 203/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9897\n",
      "Epoch 204/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0062 - acc: 0.9882\n",
      "Epoch 205/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9897\n",
      "Epoch 206/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9912\n",
      "Epoch 207/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9912\n",
      "Epoch 208/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0058 - acc: 0.9897\n",
      "Epoch 209/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9926\n",
      "Epoch 210/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0062 - acc: 0.9882\n",
      "Epoch 211/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9926\n",
      "Epoch 212/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0070 - acc: 0.9882\n",
      "Epoch 213/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9912\n",
      "Epoch 214/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0071 - acc: 0.9809\n",
      "Epoch 215/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9912\n",
      "Epoch 216/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0063 - acc: 0.9897\n",
      "Epoch 217/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9912\n",
      "Epoch 218/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9897\n",
      "Epoch 219/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9941\n",
      "Epoch 220/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9941\n",
      "Epoch 221/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0058 - acc: 0.9897\n",
      "Epoch 222/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9912\n",
      "Epoch 223/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 224/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9882\n",
      "Epoch 225/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9912\n",
      "Epoch 226/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9867\n",
      "Epoch 227/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9912\n",
      "Epoch 228/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9941\n",
      "Epoch 229/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0067 - acc: 0.9882\n",
      "Epoch 230/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9926\n",
      "Epoch 231/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9926\n",
      "Epoch 232/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9926\n",
      "Epoch 233/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0066 - acc: 0.9853\n",
      "Epoch 234/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9956\n",
      "Epoch 235/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9926\n",
      "Epoch 236/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9926\n",
      "Epoch 237/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0029 - acc: 0.9956\n",
      "Epoch 238/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0078 - acc: 0.9867\n",
      "Epoch 239/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9897\n",
      "Epoch 240/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0069 - acc: 0.9882\n",
      "Epoch 241/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9941\n",
      "Epoch 242/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9897\n",
      "Epoch 243/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9941\n",
      "Epoch 244/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9926\n",
      "Epoch 245/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9926\n",
      "Epoch 246/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9926\n",
      "Epoch 247/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9926\n",
      "Epoch 248/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0070 - acc: 0.9853\n",
      "Epoch 249/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9926\n",
      "Epoch 250/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9912\n",
      "Epoch 251/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0059 - acc: 0.9882\n",
      "Epoch 252/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9926\n",
      "Epoch 253/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9941\n",
      "Epoch 254/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9926\n",
      "Epoch 255/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9971\n",
      "Epoch 256/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9956\n",
      "Epoch 257/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9941\n",
      "Epoch 258/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9956\n",
      "Epoch 259/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9882\n",
      "Epoch 260/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9941\n",
      "Epoch 261/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0067 - acc: 0.9838\n",
      "Epoch 262/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9956\n",
      "Epoch 263/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0077 - acc: 0.9853\n",
      "Epoch 264/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0026 - acc: 0.9941\n",
      "Epoch 265/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9926\n",
      "Epoch 266/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9897\n",
      "Epoch 267/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9897\n",
      "Epoch 268/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0025 - acc: 0.9956\n",
      "Epoch 269/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9897\n",
      "Epoch 270/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9912\n",
      "Epoch 271/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9926\n",
      "Epoch 272/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0071 - acc: 0.9867\n",
      "Epoch 273/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0063 - acc: 0.9897\n",
      "Epoch 274/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9882\n",
      "Epoch 275/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9956\n",
      "Epoch 276/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9882\n",
      "Epoch 277/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9867\n",
      "Epoch 278/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9897\n",
      "Epoch 279/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9926\n",
      "Epoch 280/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9882\n",
      "Epoch 281/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0067 - acc: 0.9867\n",
      "Epoch 282/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9897\n",
      "Epoch 283/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9912\n",
      "Epoch 284/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0064 - acc: 0.9853\n",
      "Epoch 285/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9926\n",
      "Epoch 286/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9941\n",
      "Epoch 287/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0027 - acc: 0.9971\n",
      "Epoch 288/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9897\n",
      "Epoch 289/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9882\n",
      "Epoch 290/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0029 - acc: 0.9941\n",
      "Epoch 291/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0066 - acc: 0.9882\n",
      "Epoch 292/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9941\n",
      "Epoch 293/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9956\n",
      "Epoch 294/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9941\n",
      "Epoch 295/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9941\n",
      "Epoch 296/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9926\n",
      "Epoch 297/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9926\n",
      "Epoch 298/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9882\n",
      "Epoch 299/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9956\n",
      "Epoch 300/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9926\n",
      "Epoch 301/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9882\n",
      "Epoch 302/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 303/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9941\n",
      "Epoch 304/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9926\n",
      "Epoch 305/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9956\n",
      "Epoch 306/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9912\n",
      "Epoch 307/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9897\n",
      "Epoch 308/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0069 - acc: 0.9838\n",
      "Epoch 309/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9956\n",
      "Epoch 310/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9897\n",
      "Epoch 311/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9912\n",
      "Epoch 312/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0058 - acc: 0.9882\n",
      "Epoch 313/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9882\n",
      "Epoch 314/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9926\n",
      "Epoch 315/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9971\n",
      "Epoch 316/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0030 - acc: 0.9941\n",
      "Epoch 317/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9882\n",
      "Epoch 318/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0024 - acc: 0.9956\n",
      "Epoch 319/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9971\n",
      "Epoch 320/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9941\n",
      "Epoch 321/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9926\n",
      "Epoch 322/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0022 - acc: 0.9985\n",
      "Epoch 323/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0060 - acc: 0.9853\n",
      "Epoch 324/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9912\n",
      "Epoch 325/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9941\n",
      "Epoch 326/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9897\n",
      "Epoch 327/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9897\n",
      "Epoch 328/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9926\n",
      "Epoch 329/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9912\n",
      "Epoch 330/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9956\n",
      "Epoch 331/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9926\n",
      "Epoch 332/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9882\n",
      "Epoch 333/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0065 - acc: 0.9853\n",
      "Epoch 334/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0033 - acc: 0.9941\n",
      "Epoch 335/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9912\n",
      "Epoch 336/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9882\n",
      "Epoch 337/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9912\n",
      "Epoch 338/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9971\n",
      "Epoch 339/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9941\n",
      "Epoch 340/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9926\n",
      "Epoch 341/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9897\n",
      "Epoch 342/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0060 - acc: 0.9882\n",
      "Epoch 343/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9897\n",
      "Epoch 344/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9956\n",
      "Epoch 345/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0030 - acc: 0.9926\n",
      "Epoch 346/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9926\n",
      "Epoch 347/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9971\n",
      "Epoch 348/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0082 - acc: 0.9838\n",
      "Epoch 349/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9926\n",
      "Epoch 350/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0026 - acc: 0.9971\n",
      "Epoch 351/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0033 - acc: 0.9971\n",
      "Epoch 352/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0079 - acc: 0.9882\n",
      "Epoch 353/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9912\n",
      "Epoch 354/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9941\n",
      "Epoch 355/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9941\n",
      "Epoch 356/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9926\n",
      "Epoch 357/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9912\n",
      "Epoch 358/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0059 - acc: 0.9882\n",
      "Epoch 359/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9912\n",
      "Epoch 360/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9956\n",
      "Epoch 361/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9926\n",
      "Epoch 362/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0078 - acc: 0.9794\n",
      "Epoch 363/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9897\n",
      "Epoch 364/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9897\n",
      "Epoch 365/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9912\n",
      "Epoch 366/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9941\n",
      "Epoch 367/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9941\n",
      "Epoch 368/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9897\n",
      "Epoch 369/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0030 - acc: 0.9985\n",
      "Epoch 370/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0077 - acc: 0.9838\n",
      "Epoch 371/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9882\n",
      "Epoch 372/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9897\n",
      "Epoch 373/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9912\n",
      "Epoch 374/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0027 - acc: 0.9956\n",
      "Epoch 375/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9912\n",
      "Epoch 376/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9882\n",
      "Epoch 377/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9912\n",
      "Epoch 378/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9926\n",
      "Epoch 379/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9926\n",
      "Epoch 380/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9912\n",
      "Epoch 381/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9941\n",
      "Epoch 382/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9897\n",
      "Epoch 383/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9941\n",
      "Epoch 384/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9897\n",
      "Epoch 385/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9956\n",
      "Epoch 386/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9912\n",
      "Epoch 387/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9912\n",
      "Epoch 388/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9941\n",
      "Epoch 389/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9956\n",
      "Epoch 390/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0060 - acc: 0.9897\n",
      "Epoch 391/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9926\n",
      "Epoch 392/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9941\n",
      "Epoch 393/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0028 - acc: 0.9971\n",
      "Epoch 394/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0025 - acc: 0.9971\n",
      "Epoch 395/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9912\n",
      "Epoch 396/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0069 - acc: 0.9897\n",
      "Epoch 397/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9882\n",
      "Epoch 398/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9926\n",
      "Epoch 399/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0071 - acc: 0.9853\n",
      "Epoch 400/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9926\n",
      "Epoch 401/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9897\n",
      "Epoch 402/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9956\n",
      "Epoch 403/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9941\n",
      "Epoch 404/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0028 - acc: 0.9956\n",
      "Epoch 405/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9897\n",
      "Epoch 406/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9838\n",
      "Epoch 407/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0058 - acc: 0.9912\n",
      "Epoch 408/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9912\n",
      "Epoch 409/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9926\n",
      "Epoch 410/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9867\n",
      "Epoch 411/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9897\n",
      "Epoch 412/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9926\n",
      "Epoch 413/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9897\n",
      "Epoch 414/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9882\n",
      "Epoch 415/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9941\n",
      "Epoch 416/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9912\n",
      "Epoch 417/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9897\n",
      "Epoch 418/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9941\n",
      "Epoch 419/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9956\n",
      "Epoch 420/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9926\n",
      "Epoch 421/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9912\n",
      "Epoch 422/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0029 - acc: 0.9956\n",
      "Epoch 423/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0024 - acc: 0.9985\n",
      "Epoch 424/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9912\n",
      "Epoch 425/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9926\n",
      "Epoch 426/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9867\n",
      "Epoch 427/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9941\n",
      "Epoch 428/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0062 - acc: 0.9867\n",
      "Epoch 429/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9912\n",
      "Epoch 430/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9882\n",
      "Epoch 431/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9926\n",
      "Epoch 432/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0060 - acc: 0.9897\n",
      "Epoch 433/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0068 - acc: 0.9838\n",
      "Epoch 434/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9912\n",
      "Epoch 435/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0067 - acc: 0.9867\n",
      "Epoch 436/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0076 - acc: 0.9809\n",
      "Epoch 437/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0060 - acc: 0.9867\n",
      "Epoch 438/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9956\n",
      "Epoch 439/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9897\n",
      "Epoch 440/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9941\n",
      "Epoch 441/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9926\n",
      "Epoch 442/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0063 - acc: 0.9853\n",
      "Epoch 443/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9926\n",
      "Epoch 444/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9941\n",
      "Epoch 445/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9941\n",
      "Epoch 446/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0062 - acc: 0.9882\n",
      "Epoch 447/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9956\n",
      "Epoch 448/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9971\n",
      "Epoch 449/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9882\n",
      "Epoch 450/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9926\n",
      "Epoch 451/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0069 - acc: 0.9882\n",
      "Epoch 452/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0070 - acc: 0.9867\n",
      "Epoch 453/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9897\n",
      "Epoch 454/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0022 - acc: 0.9956\n",
      "Epoch 455/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9912\n",
      "Epoch 456/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9912\n",
      "Epoch 457/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9956\n",
      "Epoch 458/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9941\n",
      "Epoch 459/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0024 - acc: 0.9956\n",
      "Epoch 460/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9926\n",
      "Epoch 461/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9941\n",
      "Epoch 462/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9941\n",
      "Epoch 463/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9941\n",
      "Epoch 464/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0033 - acc: 0.9956\n",
      "Epoch 465/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9882\n",
      "Epoch 466/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0069 - acc: 0.9867\n",
      "Epoch 467/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9926\n",
      "Epoch 468/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9971\n",
      "Epoch 469/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9956\n",
      "Epoch 470/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9941\n",
      "Epoch 471/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9971\n",
      "Epoch 472/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9941\n",
      "Epoch 473/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9941\n",
      "Epoch 474/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9912\n",
      "Epoch 475/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9941\n",
      "Epoch 476/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9971\n",
      "Epoch 477/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9897\n",
      "Epoch 478/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9941\n",
      "Epoch 479/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9897\n",
      "Epoch 480/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0088 - acc: 0.9809\n",
      "Epoch 481/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9912\n",
      "Epoch 482/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0023 - acc: 0.9956\n",
      "Epoch 483/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9867\n",
      "Epoch 484/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0065 - acc: 0.9882\n",
      "Epoch 485/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9941\n",
      "Epoch 486/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0028 - acc: 0.9956\n",
      "Epoch 487/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9912\n",
      "Epoch 488/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0058 - acc: 0.9867\n",
      "Epoch 489/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0017 - acc: 0.9956\n",
      "Epoch 490/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9956\n",
      "Epoch 491/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9897\n",
      "Epoch 492/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0026 - acc: 0.9971\n",
      "Epoch 493/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9941\n",
      "Epoch 494/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0029 - acc: 0.9956\n",
      "Epoch 495/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0030 - acc: 0.9956\n",
      "Epoch 496/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9882\n",
      "Epoch 497/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0069 - acc: 0.9867\n",
      "Epoch 498/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0028 - acc: 0.9956\n",
      "Epoch 499/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9956\n",
      "Epoch 500/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9956\n",
      "Epoch 501/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9897\n",
      "Epoch 502/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9912\n",
      "Epoch 503/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9897\n",
      "Epoch 504/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9897\n",
      "Epoch 505/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0022 - acc: 0.9985\n",
      "Epoch 506/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9956\n",
      "Epoch 507/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9897\n",
      "Epoch 508/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9941\n",
      "Epoch 509/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9912\n",
      "Epoch 510/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0065 - acc: 0.9867\n",
      "Epoch 511/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9912\n",
      "Epoch 512/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0033 - acc: 0.9941\n",
      "Epoch 513/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0059 - acc: 0.9867\n",
      "Epoch 514/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9897\n",
      "Epoch 515/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9912\n",
      "Epoch 516/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0070 - acc: 0.9853\n",
      "Epoch 517/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0075 - acc: 0.9853\n",
      "Epoch 518/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9882\n",
      "Epoch 519/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9897\n",
      "Epoch 520/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9912\n",
      "Epoch 521/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9941\n",
      "Epoch 522/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9956\n",
      "Epoch 523/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9926\n",
      "Epoch 524/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9867\n",
      "Epoch 525/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0086 - acc: 0.9823\n",
      "Epoch 526/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9941\n",
      "Epoch 527/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9897\n",
      "Epoch 528/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9926\n",
      "Epoch 529/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9897\n",
      "Epoch 530/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9882\n",
      "Epoch 531/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0063 - acc: 0.9853\n",
      "Epoch 532/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9897\n",
      "Epoch 533/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9971\n",
      "Epoch 534/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9912\n",
      "Epoch 535/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9897\n",
      "Epoch 536/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0027 - acc: 0.9956\n",
      "Epoch 537/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0029 - acc: 0.9941\n",
      "Epoch 538/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0079 - acc: 0.9809\n",
      "Epoch 539/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9867\n",
      "Epoch 540/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9912\n",
      "Epoch 541/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0026 - acc: 0.9941\n",
      "Epoch 542/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0067 - acc: 0.9882\n",
      "Epoch 543/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9912\n",
      "Epoch 544/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9867\n",
      "Epoch 545/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9926\n",
      "Epoch 546/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9912\n",
      "Epoch 547/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9941\n",
      "Epoch 548/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9941\n",
      "Epoch 549/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9926\n",
      "Epoch 550/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 551/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9926\n",
      "Epoch 552/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0077 - acc: 0.9853\n",
      "Epoch 553/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9941\n",
      "Epoch 554/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9941\n",
      "Epoch 555/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9882\n",
      "Epoch 556/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9912\n",
      "Epoch 557/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9926\n",
      "Epoch 558/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0013 - acc: 0.9985\n",
      "Epoch 559/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0062 - acc: 0.9867\n",
      "Epoch 560/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9926\n",
      "Epoch 561/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0063 - acc: 0.9838\n",
      "Epoch 562/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9912\n",
      "Epoch 563/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9926\n",
      "Epoch 564/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9897\n",
      "Epoch 565/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9926\n",
      "Epoch 566/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9912\n",
      "Epoch 567/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0024 - acc: 0.9971\n",
      "Epoch 568/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9956\n",
      "Epoch 569/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9897\n",
      "Epoch 570/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9926\n",
      "Epoch 571/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9897\n",
      "Epoch 572/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9926\n",
      "Epoch 573/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9897\n",
      "Epoch 574/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9941\n",
      "Epoch 575/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0030 - acc: 0.9941\n",
      "Epoch 576/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9912\n",
      "Epoch 577/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0059 - acc: 0.9853\n",
      "Epoch 578/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0060 - acc: 0.9867\n",
      "Epoch 579/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9926\n",
      "Epoch 580/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0026 - acc: 0.9956\n",
      "Epoch 581/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9882\n",
      "Epoch 582/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9941\n",
      "Epoch 583/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9882\n",
      "Epoch 584/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0028 - acc: 0.9926\n",
      "Epoch 585/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9912\n",
      "Epoch 586/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9882\n",
      "Epoch 587/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0080 - acc: 0.9867\n",
      "Epoch 588/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9926\n",
      "Epoch 589/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9941\n",
      "Epoch 590/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9956\n",
      "Epoch 591/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9882\n",
      "Epoch 592/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0028 - acc: 0.9926\n",
      "Epoch 593/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9956\n",
      "Epoch 594/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0067 - acc: 0.9867\n",
      "Epoch 595/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9926\n",
      "Epoch 596/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 597/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0020 - acc: 0.9956\n",
      "Epoch 598/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0025 - acc: 0.9971\n",
      "Epoch 599/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0064 - acc: 0.9867\n",
      "Epoch 600/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0072 - acc: 0.9897\n",
      "Epoch 601/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0030 - acc: 0.9956\n",
      "Epoch 602/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0026 - acc: 0.9971\n",
      "Epoch 603/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0018 - acc: 0.9971\n",
      "Epoch 604/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9867\n",
      "Epoch 605/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9912\n",
      "Epoch 606/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9912\n",
      "Epoch 607/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9926\n",
      "Epoch 608/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9853\n",
      "Epoch 609/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9941\n",
      "Epoch 610/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9941\n",
      "Epoch 611/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9926\n",
      "Epoch 612/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9941\n",
      "Epoch 613/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0030 - acc: 0.9956\n",
      "Epoch 614/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0061 - acc: 0.9912\n",
      "Epoch 615/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9941\n",
      "Epoch 616/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9956\n",
      "Epoch 617/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0058 - acc: 0.9867\n",
      "Epoch 618/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9912\n",
      "Epoch 619/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9897\n",
      "Epoch 620/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0019 - acc: 0.9985\n",
      "Epoch 621/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9897\n",
      "Epoch 622/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0028 - acc: 0.9985\n",
      "Epoch 623/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9926\n",
      "Epoch 624/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9912\n",
      "Epoch 625/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9941\n",
      "Epoch 626/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9941\n",
      "Epoch 627/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9882\n",
      "Epoch 628/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9912\n",
      "Epoch 629/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9912\n",
      "Epoch 630/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9926\n",
      "Epoch 631/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9941\n",
      "Epoch 632/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0067 - acc: 0.9853\n",
      "Epoch 633/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9912\n",
      "Epoch 634/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9941\n",
      "Epoch 635/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0026 - acc: 0.9941\n",
      "Epoch 636/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9926\n",
      "Epoch 637/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0027 - acc: 0.9956\n",
      "Epoch 638/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9912\n",
      "Epoch 639/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9912\n",
      "Epoch 640/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0083 - acc: 0.9853\n",
      "Epoch 641/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0030 - acc: 0.9971\n",
      "Epoch 642/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9912\n",
      "Epoch 643/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0030 - acc: 0.9971\n",
      "Epoch 644/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9882\n",
      "Epoch 645/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9912\n",
      "Epoch 646/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9882\n",
      "Epoch 647/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9926\n",
      "Epoch 648/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9897\n",
      "Epoch 649/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9926\n",
      "Epoch 650/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0021 - acc: 0.9985\n",
      "Epoch 651/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9926\n",
      "Epoch 652/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9956\n",
      "Epoch 653/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9926\n",
      "Epoch 654/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9926\n",
      "Epoch 655/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9912\n",
      "Epoch 656/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9956\n",
      "Epoch 657/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0064 - acc: 0.9867\n",
      "Epoch 658/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9867\n",
      "Epoch 659/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9897\n",
      "Epoch 660/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9912\n",
      "Epoch 661/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9956\n",
      "Epoch 662/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9897\n",
      "Epoch 663/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9941\n",
      "Epoch 664/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0068 - acc: 0.9838\n",
      "Epoch 665/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9941\n",
      "Epoch 666/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9926\n",
      "Epoch 667/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9897\n",
      "Epoch 668/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0072 - acc: 0.9867\n",
      "Epoch 669/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0028 - acc: 0.9985\n",
      "Epoch 670/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9897\n",
      "Epoch 671/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9897\n",
      "Epoch 672/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9867\n",
      "Epoch 673/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9897\n",
      "Epoch 674/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9897\n",
      "Epoch 675/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9941\n",
      "Epoch 676/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0066 - acc: 0.9867\n",
      "Epoch 677/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0068 - acc: 0.9853\n",
      "Epoch 678/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9926\n",
      "Epoch 679/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9926\n",
      "Epoch 680/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9897\n",
      "Epoch 681/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9941\n",
      "Epoch 682/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9926\n",
      "Epoch 683/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9912\n",
      "Epoch 684/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9926\n",
      "Epoch 685/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9941\n",
      "Epoch 686/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9926\n",
      "Epoch 687/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9882\n",
      "Epoch 688/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9867\n",
      "Epoch 689/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9897\n",
      "Epoch 690/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9926\n",
      "Epoch 691/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9941\n",
      "Epoch 692/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 693/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9867\n",
      "Epoch 694/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9882\n",
      "Epoch 695/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9867\n",
      "Epoch 696/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9897\n",
      "Epoch 697/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9941\n",
      "Epoch 698/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0029 - acc: 0.9941\n",
      "Epoch 699/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0029 - acc: 0.9971\n",
      "Epoch 700/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9956\n",
      "Epoch 701/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0059 - acc: 0.9912\n",
      "Epoch 702/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0048 - acc: 0.9897\n",
      "Epoch 703/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0057 - acc: 0.9912\n",
      "Epoch 704/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0064 - acc: 0.9867\n",
      "Epoch 705/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9956\n",
      "Epoch 706/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9941\n",
      "Epoch 707/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9912\n",
      "Epoch 708/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9912\n",
      "Epoch 709/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9941\n",
      "Epoch 710/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0033 - acc: 0.9926\n",
      "Epoch 711/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9941\n",
      "Epoch 712/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0030 - acc: 0.9926\n",
      "Epoch 713/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9897\n",
      "Epoch 714/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9926\n",
      "Epoch 715/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9926\n",
      "Epoch 716/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9941\n",
      "Epoch 717/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9926\n",
      "Epoch 718/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9926\n",
      "Epoch 719/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9956\n",
      "Epoch 720/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0015 - acc: 0.9985\n",
      "Epoch 721/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9897\n",
      "Epoch 722/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9926\n",
      "Epoch 723/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9926\n",
      "Epoch 724/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9912\n",
      "Epoch 725/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9912\n",
      "Epoch 726/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9941\n",
      "Epoch 727/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0027 - acc: 0.9971\n",
      "Epoch 728/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9971\n",
      "Epoch 729/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0045 - acc: 0.9897\n",
      "Epoch 730/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0071 - acc: 0.9853\n",
      "Epoch 731/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0015 - acc: 0.9985\n",
      "Epoch 732/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9926\n",
      "Epoch 733/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9956\n",
      "Epoch 734/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9941\n",
      "Epoch 735/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0035 - acc: 0.9971\n",
      "Epoch 736/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0034 - acc: 0.9941\n",
      "Epoch 737/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0050 - acc: 0.9882\n",
      "Epoch 738/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9941\n",
      "Epoch 739/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9926\n",
      "Epoch 740/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0028 - acc: 0.9956\n",
      "Epoch 741/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0028 - acc: 0.9971\n",
      "Epoch 742/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0033 - acc: 0.9956\n",
      "Epoch 743/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0038 - acc: 0.9941\n",
      "Epoch 744/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0029 - acc: 0.9971\n",
      "Epoch 745/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0024 - acc: 0.9971\n",
      "Epoch 746/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9956\n",
      "Epoch 747/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0027 - acc: 0.9971\n",
      "Epoch 748/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9941\n",
      "Epoch 749/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0062 - acc: 0.9912\n",
      "Epoch 750/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0073 - acc: 0.9853\n",
      "Epoch 751/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9926\n",
      "Epoch 752/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9941\n",
      "Epoch 753/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9926\n",
      "Epoch 754/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0053 - acc: 0.9882\n",
      "Epoch 755/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0028 - acc: 0.9956\n",
      "Epoch 756/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9941\n",
      "Epoch 757/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0051 - acc: 0.9912\n",
      "Epoch 758/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0029 - acc: 0.9956\n",
      "Epoch 759/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9912\n",
      "Epoch 760/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0037 - acc: 0.9926\n",
      "Epoch 761/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0036 - acc: 0.9926\n",
      "Epoch 762/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0018 - acc: 0.9956\n",
      "Epoch 763/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0059 - acc: 0.9867\n",
      "Epoch 764/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0023 - acc: 0.9971\n",
      "Epoch 765/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0040 - acc: 0.9926\n",
      "Epoch 766/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0042 - acc: 0.9912\n",
      "Epoch 767/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9956\n",
      "Epoch 768/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0039 - acc: 0.9912\n",
      "Epoch 769/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0062 - acc: 0.9882\n",
      "Epoch 770/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9956\n",
      "Epoch 771/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0043 - acc: 0.9912\n",
      "Epoch 772/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0056 - acc: 0.9912\n",
      "Epoch 773/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9926\n",
      "Epoch 774/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0044 - acc: 0.9912\n",
      "Epoch 775/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0033 - acc: 0.9926\n",
      "Epoch 776/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9853\n",
      "Epoch 777/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9956\n",
      "Epoch 778/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9926\n",
      "Epoch 779/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9912\n",
      "Epoch 780/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 781/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0021 - acc: 0.9971\n",
      "Epoch 782/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9912\n",
      "Epoch 783/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0021 - acc: 0.9971\n",
      "Epoch 784/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9985\n",
      "Epoch 785/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0025 - acc: 0.9971\n",
      "Epoch 786/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0047 - acc: 0.9897\n",
      "Epoch 787/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9912\n",
      "Epoch 788/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0054 - acc: 0.9897\n",
      "Epoch 789/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0055 - acc: 0.9882\n",
      "Epoch 790/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0065 - acc: 0.9882\n",
      "Epoch 791/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0046 - acc: 0.9941\n",
      "Epoch 792/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0049 - acc: 0.9926\n",
      "Epoch 793/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9956\n",
      "Epoch 794/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0065 - acc: 0.9853\n",
      "Epoch 795/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0041 - acc: 0.9912\n",
      "Epoch 796/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0031 - acc: 0.9956\n",
      "Epoch 797/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0052 - acc: 0.9941\n",
      "Epoch 798/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0028 - acc: 0.9971\n",
      "Epoch 799/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0026 - acc: 0.9971\n",
      "Epoch 800/800\n",
      "679/679 [==============================] - 7s 10ms/step - loss: 0.0032 - acc: 0.9956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc78788f28>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, fit the model to the data\n",
    "conv_model.fit(train_images_conv, train_labels, epochs=800, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load pretrained conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('conv_model.json', 'r')\n",
    "conv_model_json = json_file.read()\n",
    "json_file.close()\n",
    "conv_model = model_from_json(conv_model_json)\n",
    "# load weights into new model\n",
    "conv_model.load_weights(\"conv_model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8acf51fac874>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Evaluate model, get metrics back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_images_conv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Calculate predictions vector from model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_images_conv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'conv_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate model, get metrics back\n",
    "stats = conv_model.evaluate(x=test_images_conv, y=test_labels)\n",
    "# Calculate predictions vector from model\n",
    "predictions = conv_model.predict(x=test_images_conv)\n",
    "predictions = np.floor(predictions + 0.5)\n",
    "\n",
    "# Get vector mask for good and bad fits and right and wrong answers\n",
    "good_fits = test_labels\n",
    "bad_fits = 1 - good_fits\n",
    "wrong_answers = np.abs(np.subtract(predictions, test_labels))\n",
    "right_answers = np.subtract(1, wrong_answers)\n",
    "# Calculate true positives (tp), as well as (tn) (fp) (fn)\n",
    "true_positives = np.multiply(right_answers, good_fits)\n",
    "true_negatives = np.multiply(right_answers, bad_fits)\n",
    "false_positives = np.multiply(wrong_answers, good_fits)\n",
    "false_negatives = np.multiply(wrong_answers, bad_fits)\n",
    "# Calculate additional metrics\n",
    "precision = np.sum(true_positives) / np.sum(true_positives + false_positives)\n",
    "recall = np.sum(true_positives) / np.sum(true_positives + false_negatives)\n",
    "\n",
    "# Print stats\n",
    "print()\n",
    "print(\"Performance on DEV set\")\n",
    "print(\"..........................\")\n",
    "print(\"Loss: \" + str(stats[0]))\n",
    "print(\"Accuracy: \" + str(stats[1]))\n",
    "print(\"Precision: \" + str(precision))\n",
    "print(\"Recall: \" + str(recall))\n",
    "\n",
    "# Print list of indices of wrong answers\n",
    "bad_list = []\n",
    "for i in range(m_test):\n",
    "    if wrong_answers[i] == 1:\n",
    "        bad_list.append(i)\n",
    "print(\"..........................\")\n",
    "print(\"List of indices of wrong guesses:\")\n",
    "print(bad_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Look at an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: [0]\n",
      "prediction: [ 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dc78cafe48>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD8CAYAAABTjp5OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQglbRCQglLBFRALi/wPuX6YPMoJ9pgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dc78cf02b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose an index \n",
    "index = 5\n",
    "# Print labels for this index\n",
    "print(\"label: \" + str(good_fits[index]))\n",
    "print(\"prediction: \" + str(predictions[index]))\n",
    "\n",
    "# Show image\n",
    "this_image = test_images[index]\n",
    "plt.imshow(np.uint8(nn_utils.get_printable_image(this_image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save convolutional model to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#plot_model(simple_model, to_file='simple_model.png')\n",
    "#SVG(model_to_dot(simple_model).create(prog='dot', format='svg'))\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = conv_model.to_json()\n",
    "with open(\"conv_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "conv_model.save_weights(\"conv_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
